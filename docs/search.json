[
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Publications",
    "section": "",
    "text": "Publications\n\n\nAlmeida, Jo√£o L. R., Gon√ßalo Charters Santos Cruz, Diogo Silva, and Tiago Oliveira. 2023. ‚ÄúApplication of Deep Learning to the Detection of Foreign Object Debris at Aerodromes‚Äô Movement Area.‚Äù In VISIGRAPP. https://www.scitepress.org/Link.aspx?doi=10.5220/0011790600003417.\n\n\nF√©lix, Miguel, Tiago Oliveira, Gon√ßalo Charters Santos Cruz, Diogo Silva, Jo√£o Alves, and Luis Santos. 2023. ‚ÄúVision-Based Cooperative Moving Path Following for Fixed-Wing UAVs.‚Äù 2023 International Conference on Unmanned Aircraft Systems (ICUAS), 782‚Äì89. https://ieeexplore.ieee.org/document/10155793/.\n\n\nRibeiro, Ricardo A., Alexandre Bernardino, Gon√ßalo Charters Santos Cruz, Diogo Silva, Lu√≠s F√©lix, Jo√£o Caetano, Duarte Folgado, et al. 2022. ‚ÄúTowards the Automation of Wildfire Monitoring with Aerial Vehicles: The FIREFRONT Project.‚Äù In ICPR Workshops. https://link.springer.com/chapter/10.1007/978-3-031-37742-6_15.\n\n\nSilva, Diogo, Helena Aidos, and Ana L. N. Fred. 2016. ‚ÄúEfficient Evidence Accumulation Clustering for Large Datasets.‚Äù In International Conference on Pattern Recognition Applications and Methods. https://www.scitepress.org/Link.aspx?doi=10.5220/0005770803670374.\n\n\n\n\nAdvisor\n\n\n2023 - Francisco Matilde - ‚ÄúStudy of the Use of Synthetic Images in the Training of Neural Networks for Detection with UAVs‚Äù\n2023 - Jos√© Rocha - ‚ÄúDesign and Implementation of a Vision-based Autoland System‚Äù\n2022 - Miguel F√©lix - ‚ÄúTarget tracking control system for multi-UAV maritime applications‚Äù\n2022 - Jo√£o Alves ‚ÄúSoftware architecture for low-cost UAVs ‚Äì An application considering automatic target tracking mission scenarios‚Äù\n2017 - F√°bio Louren√ßo ‚ÄúDesenvolvimento de Sistema de Telemetria sobre V√≠deo para UAS da FAP‚Äù"
  },
  {
    "objectID": "research/deep_segmentation_codec.html",
    "href": "research/deep_segmentation_codec.html",
    "title": "Introduction",
    "section": "",
    "text": "What is the ping of this paper? Optimized embeddings for segmentation in the form of video codec\n\nIntroduction\n\nSOTA video segmentation is deep learning based\nthe best segmentation models are heavy and not ideal for the edge\nsolutions\n\nsolution 1: use weaker, edge compatible, models\nsolution 2: transmit data over network for remote computing\n\nvideo codecs allow tunable compression of the video and make it viable for real time transmission, but after transmission the video must be decoded for full image reconstruction and then fed to segmentation models\nvideo codecs usually predict the next frame from the previous frame using reduced information by taking advantage of temporal redundancies\nif full image reconstruction is not a requirement, a specialized, edge-capable, real-time video codec might be developed to focus on segmentation performance\n\nsave time on decoding\n\n\n\n\n\nLook into it"
  },
  {
    "objectID": "blog/how-to-get-unique-values-in-an-elm-list/index.html",
    "href": "blog/how-to-get-unique-values-in-an-elm-list/index.html",
    "title": "How to get unique values in an Elm list?",
    "section": "",
    "text": "You do it like this:\nunique : List a -&gt; List a\nunique l =\n    let\n        incUnique : a -&gt; List a -&gt; List a\n        incUnique elem lst =\n            case List.member elem lst of\n                True -&gt; lst\n               False -&gt; elem :: lst\n    in\n        List.foldr incUnique [] l\nThere you go. Have fun!\n\nOh, still here? Let‚Äôs see what this is doing then.\nSo, you have a list in Elm and you want to get the unique values in it. And there is no way to write a simple imperative loop to iterate over the list. List.fold to the rescue. We have 2 folds we can use: foldl (fold left) and foldr (fold‚Ä¶ you can figure it out). The left and right refer to the associativity of the operation.\nSay you have the list [2, 2, 3, 4]. If you fold the list, it means you‚Äôll go over the list pairing 2 items and applying some function, e.g.¬†folding this list with the + operation would get us:\n( 2 + ( 2 + ( 3 + ( 4 ) ) ) )\n\n\n\nFold diagram\n\n\nThis is right associativity, by the way, so I did a foldr. We can see more clearly what‚Äôs going on looking at the diagram. There, our function f is the + operation and our seed is 0.\nThe foldl would look like this:\n( ( ( ( 2 ) + 2 ) + 3 ) + 4 )\nIn Elm we have List.foldl and List.foldr. In addition to the function to apply and the list, we also have to supply a seed value to apply to the first element of the list, e.g.¬†if our seed was 0, we‚Äôd have a foldr like this:\n( 2 + ( 2 + ( 3 + ( 4 + 0) ) ) )\nThis is how folding works. We can use it for more advanced data structure traversal, but we‚Äôll only use it to find unique values here. We will start with an empty list (our seed) and check if the elements in the original list are n this new list. If they are, we do nothing. If they are not, we add them to that list (or rather we create a new list with the elements of that list plus the new element, since there‚Äôs is no mutability in Elm land).\nLet‚Äôs define our function:\nincUnique : a -&gt; List a -&gt; List a\nincUnique elem lst =\n case List.member elem lst of\n True -&gt; lst\n False -&gt; elem :: lst\nThis function receives a list element and a list. If the element is a member of that list, it returns the list. If it‚Äôs not, it returns a new list containing all the elements of the received list plus the received element. Then we use the fold with this function.\nsomeList = [ 2, 2, 3, 4]\nList.foldr incUnique [] someList\nHere‚Äôs what‚Äôs happening\n( incUnique 2 ( incUnique 2 ( incUnique 3 ( incUnique 4 [] ) ) ) )\n( incUnique 2 ( incUnique 2 ( incUnique 3 [4] ) ) )\n( incUnique 2 ( incUnique 2 [3, 4] ) )\n( incUnique 2 [2, 3, 4] )\n( [2, 3, 4] )\nSee, we‚Äôre folding from the right. What if we folded from the left?\n( incUnique 4 ( incUnique 3 ( incUnique 2 ( incUnique 2 [] ) ) ) )\n( incUnique 4 ( incUnique 3 ( incUnique 2 [2] ) ) )\n( incUnique 4 ( incUnique 3 [2] ) )\n( incUnique 4 [3, 2] )\n( [4, 3, 2] )\nIt‚Äôs less clear that we‚Äôre folding from the left because the list element is always the left operand of the function. This caused the list to look inverted in the expression. As it turns out, our final result also inverts the original list, with the duplicates removed. This is because our function incUnique adds new elements to the front of the list. If it added to the back of the list, foldr would invert the list and foldl would preserve order. Go back to the diagram above and imagine what it would like for a left fold.\nPutting it all together:\nunique : List a -&gt; List a\nunique l =\n    let\n        incUnique : a -&gt; List a -&gt; List a\n        incUnique elem lst =\n        case List.member elem lst of\n            True -&gt; lst\n            False -&gt; elem :: lst\n     in\n    List.foldr incUnique [] l"
  },
  {
    "objectID": "blog/elm-elm-ui-and-the-building-of-a-dropdown-part-i/index.html",
    "href": "blog/elm-elm-ui-and-the-building-of-a-dropdown-part-i/index.html",
    "title": "Elm, elm-ui and the building of a dropdown‚Ää‚Äî‚ÄäPart I",
    "section": "",
    "text": "If you‚Äôre getting into Elm and still handling CSS files, just thrash them. Really. Go ahead and do it, because in Elm, we have the beautiful Elm-UI. You‚Äôll get to write design in a language that‚Äôs actually understandable. However, Elm-UI probably still doesn‚Äôt have everything you might need. One simple thing it doesn‚Äôt have builtin is a dropdown, something you see everywhere.\nFollow along and learn how to build a barebones dropdown. In part II, we‚Äôll make a parameterized version using Elm‚Äôs powerful types. More specifically, you‚Äôll master parameterized types! You can find it here.\n\nSetup\nStart a new a Elm project with elm init and create a Main.elm file inside the src folder. You can also follow along using Ellie for this first part (when we start using parametrized types we‚Äôll create a new module for a reusable dropdown).\nInstall elm-ui with elm install mdgriffith/elm-ui.\nStart with the following barebones structure:\nmodule Main exposing (main)\n\nimport Browser\nimport Html\n\nimport Element as E\nimport Element.Background as Background\nimport Element.Border as Border\nimport Element.Events as Events\n\ntype alias Model =\n    { }\n\n        \ninitialModel : Model\ninitialModel =\n    { \n    }\n\ntype Msg\n    = NoAction\n      \n\nupdate : Msg -&gt; Model -&gt; Model\nupdate msg model =\n    case msg of\n        NoAction -&gt;\n            model\n\nview : Model -&gt; Html.Html Msg\nview model =\n    E.layout\n        []\n        (\n        E.column\n            [ E.centerX\n            , E.centerY\n        ]\n            [ E.text \"You favorite food is:\"\n            , E.text \"... the best food.\"\n            ]\n        )\n\nmain : Program () Model Msg\nmain =\n    Browser.sandbox\n        { init = initialModel\n        , view = view\n        , update = update\n        }\nelm make src/main.elm and go the index.html file created in the project folder. Right off the start, you get a nice centered layout like this:\n\nUau, look at the code to center the column. Isn‚Äôt life wonderful? I‚Äôll never get tired of this.\n\n\nThe dropdown\nOk, let‚Äôs focus. What is a dropdown anyway? A dropdown allows the user to choose one option from a predefined list. Let‚Äôs build a simple dropdown to select our favorite food. We need some options to choose from. We‚Äôll create a Food type that has an id, name and foodType, which can be FastFood or Regional.\ntype FoodType\n    = FastFood\n    | Regional\n        \ntype alias Food =\n    { id : Int\n    , name : String\n    , foodType : FoodType\n    }\n\nfoodList : List Food\nfoodList =\n    [ Food 0 \"Hotdog\" FastFood\n    , Food 1 \"Hamburguer\" FastFood\n    , Food 2 \"Taco\" FastFood\n    , Food 3 \"Francesinha aka Little French\" Regional\n    , Food 4 \"Sauerkraut\" Regional\n    , Food 5 \"Kimchi\" Regional\n    ]\nAdd that after the imports. Our model needs to know what is the currently selected favorite food and also if we‚Äôre currently selecting any food from the dropdown or not.\ntype alias Model =\n    { favoriteFood : Maybe Food\n    , status : Status}\n\ntype Status\n    = Normal\n    | SelectFood\n\ninitialModel : Model\ninitialModel =\n    { favoriteFood = Nothing\n    , status = Normal\n    }\nfavoriteFood might have a Food that was selected, or not, in which case it will be Nothing (which is also the starting value, since the user hasn‚Äôt selected anything yet). Status just tells us whether we‚Äôre currently selecting a food from the list or not. When the user clicks the dropdown, status changes to SelectFood. When the user clicks one of the dropdown options it goes back to Normal (which is also the starting status).\nFor now, let‚Äôs start working on actually designing the dropdown in our view. Let‚Äôs create a column with all our possible options written.\nview : Model -&gt; Html.Html Msg\nview model =\n    let\n        selectedFoodName = \n            case model.favoriteFood of\n                Nothing -&gt; \"No food selected. Click here to select.\"\n                Just food -&gt; food.name\n        dropdown = \n            E.el\n                [ Border.width 1\n                , Border.dashed\n                , E.padding 3\n                , Events.onClick ClickedSelectFood\n                ]\n                (E.text selectedFoodName)\n    in\n    E.layout\n        []\n        (\n        E.column\n            [ E.centerX\n            , E.centerY\n        ]\n            [ E.text \"You favorite food is:\"\n            , dropdown\n            , E.text \"... the best food.\"\n            ]\n        )\nWe just created a placeholder for the name of our favorite food. It already manages the case when there is no food selected. And, if we click on the box, we‚Äôll send the ClickedSelectFood message. We need to create this message and deal with it in the update.\ntype Msg\n    = NoAction\n    | ClickedSelectFood\n      \n\nupdate : Msg -&gt; Model -&gt; Model\nupdate msg model =\n    case msg of\n        NoAction -&gt;\n            model\n        ClickedSelectFood -&gt;\n            { model | status = SelectFood }\nWhen we click on the dropdown, a ClickedSelectFood is sent and our status changes to SelectFood. Makes sense, right? We‚Äôll need to do something with that status, but for now, you‚Äôll get something like this:\n\nWhat we want is for a list of food options to appear below the dropdown, and over the remaining content, without changing the existing layout. Thankfully, elm-ui has a nice attribute for this, it‚Äôs called below. The content to be added will be inside this attribute. We‚Äôll create a function to view a list of foods and a function to view a single food and compose them inside our view.\nview : Model -&gt; Html.Html Msg\nview model =\n    let\n        selectedFoodName = \n            case model.favoriteFood of\n                Nothing -&gt; \"No food selected. Click here to select.\"\n                Just food -&gt; food.name\n                dropdown =\n            case model.status of\n                Normal -&gt;\n                    E.el\n                        [ Border.width 1\n                        , Border.dashed\n                        , E.padding 3\n                        , Events.onClick ClickedSelectFood\n                        ]\n                        (E.text selectedFoodName)\n                SelectFood -&gt;\n                    E.el\n                        [ Border.width 1\n                        , Border.dashed\n                        , E.padding 3\n                        , E.below (viewFoodList foodList)\n                        ]\n                        (E.text selectedFoodName)\n    in\n    E.layout\n        []\n        (\n        E.column\n            [ E.centerX\n            , E.centerY\n        ]\n            [ E.text \"You favorite food is:\"\n            , dropdown\n            , E.text \"... the best food.\"\n            ]\n        )\n\nviewFoodList : List Food -&gt; E.Element Msg\nviewFoodList foods =\n    E.column\n        [ ]\n        &lt;|\n            List.map viewFood foods\n\noverColor : E.Color\noverColor = E.rgb 0.9 0.9 0.1\n\nviewFood : Food -&gt; E.Element Msg\nviewFood food =\n    E.el\n        [ E.width E.fill\n        , E.mouseOver [Background.color overColor]\n        ]\n        (E.text food.name)\nThat‚Äôs a bit step. The important part is inside the let block in view. If status is SelectFood, then we will have a list of Element.text with the names of the foods attached to the below attribute. Otherwise, we‚Äôll not use that attribute. Also note that the onClick attribute only appears when status is Normal. This is because is we kept it on both cases, the event would be triggered when clicked one of the options, because this list lives inside the dropdown element. We don‚Äôt want that. The ClickedSelectFood message should only be sent then the status is Normal. If we‚Äôre already selecting an option from the food list, it doesn‚Äôt make sense to send a message that triggers the logic to open the dropdown (it‚Äôs already opened). Now, when we click the dropdown, we‚Äôll get the desired list.\n\nIn viewFood, we already added some nice visual sugar for changing the background color of the option where the mouse is.\nAs you can inspect, the list is drawn over the rest of the content. That‚Äôs why the layout is not changed in the process. But this also means that we‚Äôre now seeing the content below. We need to fill the background of all options.\nwhite : E.Color\nwhite = E.rgb 1 1 1\n\nviewFood : Food -&gt; E.Element Msg\nviewFood food =\n    E.el\n        [ E.width E.fill\n        , E.mouseOver [Background.color overColor]\n        , Background.color white\n        ]\n        (E.text food.name)\n\nWe could style it more, add a little padding, making sure the options have the same width, etc., but let‚Äôs focus on the logic. There is only one thing missing: implementing the logic for when we actually select an option. When we click an option, a message has to be sent specifying which food was clicked on, save it in the model and revert status back to Normal.\ntype Msg\n    = NoAction\n    | ClickedSelectFood\n    | ClickedDropdownFood Food\n      \n\nupdate : Msg -&gt; Model -&gt; Model\nupdate msg model =\n    case msg of\n        NoAction -&gt;\n            model\n            \n        ClickedSelectFood -&gt;\n            { model | status = SelectFood }\n            \n        ClickedDropdownFood food -&gt;\n            { model | status = Normal, favoriteFood = Just food }\n\nviewFood : Food -&gt; E.Element Msg\nviewFood food =\n    E.el\n        [ E.width E.fill\n        , E.mouseOver [Background.color overColor]\n        , Background.color white\n        , Events.onClick (ClickedDropdownFood food)\n        ]\n        (E.text food.name)\nWe added the ClickedDropdownFood message, which will be sent when we click one of the foods of the list (see the onClick event in viewFood). When update receives this message, status reverts to Normal and the new favoriteFood is the one we clicked on. view then renders everything as it should.\n\nNow you know how to create a simple dropdown. What if you need multiple dropdowns? What if they‚Äôre selecting different things? That‚Äôs what we‚Äôll cover in part II, where we‚Äôll create a reusable component that will receive any type and display it like we did here.\nWhat do you think? How would you improve on this? Drop me a message at blog@diogoaos.com."
  },
  {
    "objectID": "blog/2023-08-sorting-faces/pt2.html",
    "href": "blog/2023-08-sorting-faces/pt2.html",
    "title": "The pain of sorting images by faces II",
    "section": "",
    "text": "After playing around further with the clustering parameters of the prototype in part I, this only took me so far. To finally be done with this task, I built on what I had in part I and added:\n\na strategy to continually break clusters;\na labeling interface and export utility.\n\n\n\nClustering\nDefining the appropriate number of clusters is not straightforward. Faces are clustered together according to the distance of their embeddings. In my case, I used Euclidean distance and single linkage. Why single linkage? I wanted to make sure a face joined a cluster if it was similar to any of the cluster‚Äôs faces, instead of an average of the faces, or even the longest distanced face within the cluster.\nStill, the faces of 2 different people might be more similar between them, than either are to detection outliers (e.g.¬†a flower). This means a cluster would be created for the flower, and the 2 people would be clustered together if too few clusters are allowed. For this reason, the adopted strategy was to start with a small number of clusters and increase it until the biggest cluster was sufficiently small.\nI don‚Äôt love this strategy: it‚Äôs another parameter to tune, it will be sensitive to the photo collection, and it‚Äôs hacky. But, in the end, I just wanted my collection grouped by faces, and it managed that. This step has a lot of room for improvement.\n\n\nUI\nIt turns out the UI is one of the most important parts of this mini-project. Default settings for the clustering alone can only take the user so far. Iterative clustering and labeling are key to quality people recognition. Currently, this is accomplished with a hammered CLI for basic interaction and OpenCV GUI for cluster display. If I were to continue this project, it would be nice to have a web based interface that managed labels and would allow for more complex operations, such as breaking apart clusters.\n\nThe whole codebase lives in the facegroups repository. The process that produced the groups of images I wanted has 3 steps:\n\nface detection: explained in part I and implemented in facegroups/extract.py (it took around 1h to process ~1000 high resolution images);\nface clustering: partly explained part I, uses agglomerative clustering and the strategy mentioned above and is implemented in facegroups/cluster.py;\ncluster labeling and export tool: basic CLI/GUI tool for a user to label precomputed clusters, implemented in facegroups/label_clusters.py.\n\nI‚Äôm done with this project for now, but the next steps would be:\n\nimproving the UI, to allow iterative and interactive clustering and labeling;\nimproving the clustering and adding logic to suggest cluster merge for the user to validate."
  },
  {
    "objectID": "blog/2023-08-sorting-faces/index.html",
    "href": "blog/2023-08-sorting-faces/index.html",
    "title": "The pain of sorting images by faces I",
    "section": "",
    "text": "A few friends and family have recently asked me to share the photos of an event. There are a couple thousands of photos, with dozens of different people, so I wanted to share only the most relevant to them. Rather than spending an hour or so doing this, I wanted to use face recognition to help with this task.\nGoogle Photos does this quite well, but the photo quality after upload is reduced and I‚Äôve already hit my storage limit anyway. There are a few programs that do this as well. Of the free ones, I wanted something that worked in Linux. Shotwell is reported to have this ability, but I couldn‚Äôt get it to work. DigiKam also has it, but I found it to be very lacking‚Ää-‚Ääespecially the recognition feature. So, I decided to learn a bit more about face recognition and see if I could come up with something quickly and easily.\nI looked for simple frameworks to help me accomplish this. I found DeepFace (Serengil and Ozpinar 2020; ‚ÄúDeepFace GitHub Repository‚Äù n.d.), but after an hour or so, I couldn‚Äôt get it to work as I wanted. The high-level API didn‚Äôt lend well to the workflow I wanted. And when trying to use the low-level API, I hit some Tensorflow-related problems related to the lack of GPU on my system. I then found FaceNet (Timesler; Schroff, Kalenichenko, and Philbin 2015). It provides tools for face detection and generating embeddings that can be used with standard ML techniques for recognition. It works well and has a PyPI package ready to go.\nIn general, Face Recognition is a multi-part process (Serengil 2020)\n\nDetection (detect faces in photos)\nAlignment (align the faces, I actually skipped this step)\nRepresentation (projecting the original face into a feature space that can be used for similarity matching)\nVerification (2 faces match or not, according to some metric)\n\nFor detection, I used MTCNN (Multi-Task Cascaded Convolutional Neural Networks) (Zhang et al. 2016), already included in the FaceNet package. From here, I got the faces, which were stored in a separate folder and a simple database matching the source image for each face.\nFor representation, I used the InceptionResnetV1 (Szegedy et al. 2017) model with weights pre-trained on vggface2 (Cao et al. 2018). I got 512-length embeddings from this model.\nFinally, for verification, I used a simple clustering algorithm. Because the same person might generate different clusters, I wanted to use a constrained clustering algorithm, so that I might add the constraints later on, with minimal impact on the pipeline. I chose Agglomerative Clustering (‚Äúscikit-learn Documentation: Agglomerative Clustering‚Äù n.d.), which is also what is used to showcase face clustering in the FaceNet original paper (Schroff, Kalenichenko, and Philbin 2015).\nFrom my quick experiments, using only single linkage and varying the number of clusters, the algorithm works quite well, which highlights the quality of the embeddings. The best result was using 300 clusters, discarding clusters with less than 5 faces. I got everyone. Some people were split into 2-3 clusters. Usually, this happened when there was a group of photos with different lighting conditions. When I used too few clusters, some people were clumped together in the same cluster. There was one cluster that had nearly all the women from the event.\nI first found it odd that good results started emerging with a very high number of clusters. There were not 300 people in the subset of images I first processed. However, there were a few non-faces and partial faces detected. These outliers will have a higher distance to real faces, but also to other outliers, meaning they will be kept on singleton clusters. I didn‚Äôt count how many of these outliers were present in my dataset, so I can‚Äôt yet be sure this is the main reason.\nThe next step will be to play around with the clustering algorithm and use the current clustering to constrain the algorithm. I‚Äôll share the codebase soon.\n\n\n\n\nReferences\n\nCao, Qiong, Lixuan Shen, Weidi Xie, Omkar M. Parkhi, and Andrew Zisserman. 2018. ‚ÄúVggface2: A Dataset for Recognising Faces Across Pose and Age.‚Äù In 2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018), 67‚Äì74. IEEE. https://arxiv.org/pdf/1710.08092.pdf.\n\n\n‚ÄúDeepFace GitHub Repository.‚Äù n.d. Accessed August 28, 2023. https://github.com/serengil/deepface.\n\n\nSchroff, Florian, Dmitry Kalenichenko, and James Philbin. 2015. ‚ÄúFacenet: A Unified Embedding for Face Recognition and Clustering.‚Äù In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 815‚Äì23. https://arxiv.org/pdf/1503.03832.pdf.\n\n\n‚Äúscikit-learn Documentation: Agglomerative Clustering.‚Äù n.d. Accessed August 28, 2023. https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html.\n\n\nSerengil, Sefik Ilkin. 2020. ‚ÄúA Gentle Introduction to Face Recognition in Deep Learning.‚Äù 2020. https://sefiks.com/2020/05/01/a-gentle-introduction-to-face-recognition-in-deep-learning/.\n\n\nSerengil, Sefik Ilkin, and Alper Ozpinar. 2020. ‚ÄúLightFace: A Hybrid Deep Face Recognition Framework.‚Äù In 2020 Innovations in Intelligent Systems and Applications Conference (ASYU), 23‚Äì27. IEEE. https://doi.org/10.1109/ASYU50717.2020.9259802.\n\n\nSzegedy, Christian, Sergey Ioffe, Vincent Vanhoucke, and Alex Alemi. 2017. ‚ÄúInception-V4, Inception-ResNet and the Impact of Residual Connections on Learning.‚Äù In Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 31. 1. https://arxiv.org/pdf/1602.07261.pdf.\n\n\nTimesler. ‚ÄúFacenet-PyTorch: A PyTorch Implementation of the FaceNet Facial Recognition Model.‚Äù https://github.com/timesler/facenet-pytorch.\n\n\nZhang, Kaipeng, Zhanpeng Zhang, Zhifeng Li, and Yu Qiao. 2016. ‚ÄúJoint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks.‚Äù IEEE Signal Processing Letters 23 (10): 1499‚Äì1503. https://arxiv.org/pdf/1604.02878.pdf."
  },
  {
    "objectID": "blog/reusable-dropdown-in-elm-with-parameterized-types-part-ii/index.html",
    "href": "blog/reusable-dropdown-in-elm-with-parameterized-types-part-ii/index.html",
    "title": "Reusable dropdown in Elm with parameterized types ‚Äî part II",
    "section": "",
    "text": "Ever needed to have a dropdown on a form? Or on a configuration page? Maybe multiple dropdowns for different ends with different types? elm-ui is great, but it doesn‚Äôt offer a primitive for dropdowns. In this guide, you‚Äôll build a reusable dropdown and, along the way, you‚Äôll learn about parametrized types.\nWe‚Äôll build on top of work done in part I, but if you‚Äôre familiar with Elm, you should have no trouble jumping right in. The complete code from part I is available in this Github repository.\nIn part I we built this:\n\nThe way we did it, we can‚Äôt reuse it for other types. We‚Äôll build a simple reusable component with consistent styling that can be reused by calling a function in our views and little added logic.\nHere‚Äôs a refresher of the view and update logic of what we built in part I:\n\ntype alias Model =\n    { favoriteFood : Maybe Food\n    , status : Status}\n\ntype Status\n    = Normal\n    | SelectFood\n\nview : Model -&gt; Html.Html Msg\nview model =\n    let\n        selectedFoodName = \n            case model.favoriteFood of\n                Nothing -&gt; \"No food selected. Click here to select.\"\n                Just food -&gt; food.name\n                dropdown =\n            case model.status of\n                Normal -&gt;\n                    E.el\n                        [ Border.width 1\n                        , Border.dashed\n                        , E.padding 3\n                        , Events.onClick ClickedSelectFood\n                        ]\n                        (E.text selectedFoodName)\n                SelectFood -&gt;\n                    E.el\n                        [ Border.width 1\n                        , Border.dashed\n                        , E.padding 3\n                        , E.below (viewFoodList foodList)\n                        ]\n                        (E.text selectedFoodName)\n    in\n    E.layout\n        []\n        (\n        E.column\n            [ E.centerX\n            , E.centerY\n        ]\n            [ E.text \"You favorite food is:\"\n            , dropdown\n            , E.text \"... the best food.\"\n            ]\n        )\n\ntype Msg\n    = NoAction\n    | ClickedSelectFood\n      \n\nupdate : Msg -&gt; Model -&gt; Model\nupdate msg model =\n    case msg of\n        NoAction -&gt;\n            model\n        ClickedSelectFood -&gt;\n            { model | status = SelectFood }\nFor a single dropdown this is fine, but if we had, say, 5 dropdowns, we‚Äôd need 5 different Status. That is a lot of boilerplate. We‚Äôll create a new Dropdown type to keep the state and value of the dropdown.\nLet‚Äôs change that. Associated with dropdown is a list of options and a function that will convert an option to a string (to display). We‚Äôll also need a message to trigger when an option is selected.\ntype Dropdown a\n    = Normal (Maybe a)\n    | Select\nThis is a parameterized type. This dropdown can receive any type (foods, countries, people, cars, whatever you need). See that a there? That‚Äôs the type variable.\nThis Normal is in conflict with our previous Status type. Go ahead and delete that entire type. Now, we‚Äôll change the model to reference this dropdown type. we‚Äôll need a Food dropdown - the Food will be the type of the Dropdown.\nWhile we‚Äôre at it, change the initial model too.\ntype alias Model =\n    { favoriteFood : Maybe Food\n    }\n\ninitialModel : Model\ninitialModel =\n    { favoriteFood = Normal Nothing\n    }\nWe also don‚Äôt need status anymore. Dropdown will keep its state within the type.\nNext, let‚Äôs tackle update. Since we don‚Äôt have Status anymore, we‚Äôll need to start using the new Dropdown type here too.\nupdate : Msg -&gt; Model -&gt; Model\nupdate msg model =\n    case msg of\n        NoAction -&gt;\n            model\n            \n        ClickedSelectFood -&gt;\n            { model | favoriteFood = Select }\n            \n        ClickedDropdownFood food -&gt;\n            { model | favoriteFood = Normal (Just food) }\nLet‚Äôs head over to the view function now. Go ahead and delete the entire let expression. Delete the viewFood and viewFoodList while you‚Äôre at it. We‚Äôll replace these with generic functions. Now, create a dropdownView function.\ndropdownView : Dropdown a -&gt; List a -&gt; (a -&gt; String) -&gt; Msg -&gt; (a -&gt; Msg) -&gt; E.Element Msg\ndropdownView dropdownState options toString openMenuMsg clickedOptionMsg =\n    let\n        selectedName =\n            case dropdownState of\n                Normal (Just someA) -&gt; toString someA\n                _ -&gt; \"Click to select\"\n        menu : E.Element Msg\n        menu =\n            if not (dropdownState == Select) then\n                    E.el\n                        [ Border.width 1\n                        , Border.dashed\n                        , E.padding 3\n                        , Events.onClick openMenuMsg\n                        ]\n                        (E.text selectedName)\n            else\n                let\n                    mouseOverColor : E.Color\n                    mouseOverColor = E.rgb 0.9 0.9 0.1\n                                \n                    backgroundColor : E.Color\n                    backgroundColor = E.rgb 1 1 1\n                            \n                    viewOption : a -&gt; E.Element Msg\n                    viewOption option =\n                        E.el\n                            [ E.width E.fill\n                            , E.mouseOver [Background.color overColor]\n                            , Background.color white\n                            , Events.onClick (clickedOptionMsg option)\n                            ]\n                            (E.text &lt;| toString option)\n\n                    viewOptionList : List a -&gt; E.Element Msg\n                    viewOptionList inputOptions =\n                        E.column [] &lt;|\n                            List.map viewOption inputOptions\n                                     \n                in\n                    E.el\n                        [ Border.width 1\n                        , Border.dashed\n                        , E.padding 3\n                        , E.below (viewOptionList options)\n                        ]\n                        (E.text selectedName)\n    in\n        menu\nLet‚Äôs go step by step. There are 5 arguments to the function. Yes, that‚Äôs a lot. What do they do?\n\ndropdownState: gives the state of the dropdown to draw.\noptions: gives the list of possible options from which the user can select.\ntoString: function to convert the type of the option to a string\nopenMenuMsg: the message that will be triggered when the user clicks the dropdown to select an option.\nclickedOptionMsg: the message that will be triggered when the user selects an option.\n\nWe‚Äôll simplify this further, but that will come later. For now, pay attention to the let expression - all the logic resides there. It‚Äôs pretty much what we had before in the original view. The viewFood was replaced by viewOption, which now is parameterized on a. Idem for viewFoodList and viewOptionList. All the styling is the same. The big different now is the conditions. We now check whether the dropdown state is on Select (meaning the select menu is open).\nOn view, we‚Äôll now have the following:\nview : Model -&gt; Html.Html Msg\nview model =\n    E.layout\n        []\n        (\n        E.column\n            [ E.centerX\n            , E.centerY\n        ]\n            [ E.text \"You favorite food is:\"\n            , dropdownView model.favoriteFood foodList .name ClickedSelectFood ClickedDropdownFood\n            , E.text \"... the best food.\"\n            ]\n        )\nThe dropdown state is the favoriteFood in the model. foodList is the list of foods defined in [TODO add link] part I. .name is the function that will be used to convert Food to String. Then we have the two messages triggered by the two relevant events.\nAnd that‚Äôs it. We now, once again, have a working dropdown. Lets simplify this further. Let‚Äôs have a single message for each dropdown and keep the option list inside the dropdown state.\n\nFurther simplification\nThe first modification is to add the option list to the Select variant of Dropdown.\ntype Dropdown a\n    = Normal (Maybe a)\n    | Select (List a)\nThen, we just have to follow the compiler error messages and make some changes in update and in the view conditions.\nupdate : Msg -&gt; Model -&gt; Model\nupdate msg model =\n    case msg of\n        -- ...\n\n        ClickedSelectFood -&gt;\n            { model | favoriteFood = Select foodList }\n\n        -- ...\n            \n               \n\ndropdownView : Dropdown a -&gt; (a -&gt; String) -&gt; Msg -&gt; (a -&gt; Msg) -&gt; E.Element Msg\ndropdownView dropdownState toString openMenuMsg clickedOptionMsg =\n    let\n        selectedName =\n            case dropdownState of\n                Normal (Just someA) -&gt; toString someA\n                _ -&gt; \"Click to select\"\n\n        menu : E.Element Msg\n        menu =\n            case dropdownState of\n                Select options -&gt;\n                    let\n                        mouseOverColor : E.Color\n                        mouseOverColor = E.rgb 0.9 0.9 0.1\n                                         \n                        backgroundColor : E.Color\n                        backgroundColor = E.rgb 1 1 1\n                                          \n                        viewOption : a -&gt; E.Element Msg\n                        viewOption option =\n                            E.el\n                                [ E.width E.fill\n                                , E.mouseOver [Background.color overColor]\n                                , Background.color white\n                                , Events.onClick (clickedOptionMsg option)\n                                ]\n                                (E.text &lt;| toString option)\n                                    \n                        viewOptionList : List a -&gt; E.Element Msg\n                        viewOptionList inputOptions =\n                            E.column [] &lt;|\n                                List.map viewOption inputOptions\n                                            \n                    in\n                        E.el\n                            [ Border.width 1\n                            , Border.dashed\n                        , E.padding 3\n                        , E.below (viewOptionList options)\n                        ]\n                        (E.text selectedName)                \n                _ -&gt;\n                    E.el\n                        [ Border.width 1\n                        , Border.dashed\n                        , E.padding 3\n                        , Events.onClick openMenuMsg\n                        ]\n                        (E.text selectedName)\n    in\n        menu\n    \n                            \nview : Model -&gt; Html.Html Msg\nview model =\n    E.layout\n        []\n        (\n        E.column\n            [ E.centerX\n            , E.centerY\n        ]\n            [ E.text \"You favorite food is:\"\n            , dropdownView  model.favoriteFood .name ClickedSelectFood ClickedDropdownFood\n            , E.text \"... the best food.\"\n            ]\n        )\nThe if expression was replaced by a case, since now we needed to get the option list from the dropdown Select variant.\nNow, let‚Äôs have a single message for each dropdown. We‚Äôll create a new type, specifying the available actions, namely, open the menu and click an option. Afterwards, we‚Äôll just need a message for each dropdown. From there, it‚Äôs just following the compiler errors to refactor the rest of the program.\ntype DropdownAction a\n    = OpenList\n    | ClickedOption a\n\ntype Msg\n    = FoodDropdown (DropdownAction Food)\nDropdownAction is also parameterized and we now have a single message for our food dropdown, which contains a DropdownAction triggered by user activity. We also got rid of the NoAction message which had been dragging along since the first example of part I.\nNext, we‚Äôll change the logic in update.\nupdate : Msg -&gt; Model -&gt; Model\nupdate msg model =\n    case msg of\n        FoodDropdown action -&gt;\n            case action of\n                OpenList -&gt;\n                    { model | favoriteFood = Select foodList }\n                ClickedOption food -&gt;\n                    { model | favoriteFood = Normal (Just food) }\nOur two previous messages, in essence, are still there, but now they‚Äôre just variants of the possible dropdown actions, typified in DropdownAction. This actually makes a lot more sense. If we wanted to add more actions to a dropdown, we wouldn‚Äôt have to change this message, just the type and the resulting logic.\nThe last bit is the view. Since there is very little change, I‚Äôll only cover the few lines that are refactored. First of all, we now only receive one message (which is actually a function that receives a DropdownAction and transforms it in a Msg, since all type variants also double up as functions).\ndropdownView : Dropdown a -&gt; (a -&gt; String) -&gt; (DropdownAction a -&gt; Msg) -&gt; E.Element Msg\ndropdownView dropdownState toString toMsg =\nAfterwards, we need to replace the onClick events by the corresponding DropdownAction messages. First, inside viewOption.\n, Events.onClick (toMsg (ClickedOption option))\nThen, inside the Element that renders the default (closed) dropdown.\n, Events.onClick (toMsg OpenList)\nAnd there you have it. After around 1500 words (counting code, that‚Äôs cheating you say, yes I know, but I still had to write it), we‚Äôre exactly where we were in the beginning. Ah‚Ä¶ the circle of life.\n\n\n\nReusable%20dropdown%20in%20Elm%20with%20parameterized%20types%20%20d1e26d5077354f649483c7b693031587/Untitled.png\n\n\nBut now, we can add another dropdown with very little work. Let‚Äôs add a favorite car dropdown. We create a Car type, add it to the Model, initialize it in initialModel, create a CarDropdown message, basically copy / paste the logic from the FoodDropdown and finally add two lines in view.\n\ntype alias Model =\n    { favoriteFood : Dropdown Food\n    , favoriteCar : Dropdown Car\n    }\n\ntype alias Car = {id : Int, name: String}\n\ntype Msg\n    = FoodDropdown (DropdownAction Food)\n    | CarDropdown (DropdownAction Car)\n\nupdate : Msg -&gt; Model -&gt; Model\nupdate msg model =\n    case msg of\n        -- ...\n\n        CarDropdown action -&gt;\n            case action of\n                OpenList -&gt;\n                    { model | favoriteCar = Select [Car 0 \"BMW\", Car 1 \"Tesla\"] }\n                ClickedOption car -&gt;\n                    { model | favoriteCar = Normal (Just car) }\n\nview : Model -&gt; Html.Html Msg\nview model =\n    E.layout\n        []\n        (\n        E.column\n            [ E.centerX\n            , E.centerY\n        ]\n            [ E.text \"You favorite food is:\"\n            , dropdownView  model.favoriteFood .name FoodDropdown\n            , E.text \"... the best food.\"\n            , E.text \"Favorite car:\"\n            , dropdownView model.favoriteCar .name CarDropdown\n            ]\n        )\n\nWe‚Äôre done here! A simple, reusable dropdown. If you‚Äôve never used parameterized types, take a moment to ponder their potential and simplicity. We can actually simplify this further depending on the needs, e.g.¬†having a function to update a dropdown based on its inputs. One of the advantages is the consistent style of every dropdown (or the lack of it in these examples). You can check the full code in this Github repository.\nIn part III, we‚Äôll use the knowledge and practice of parameterized types to make something a little more complex. We‚Äôll build a component that will allow us to choose several options, or none depending on the parameters. It will all be configurable. It will basically be a dropdown on steroids.\nWhat do you think? How would you improve on this? Drop me a message at blog@diogoaos.com."
  },
  {
    "objectID": "blog/bypass-firewalls-and-routers-with-reverse-tunnels/index.html",
    "href": "blog/bypass-firewalls-and-routers-with-reverse-tunnels/index.html",
    "title": "Bypass firewalls and routers with reverse tunnels",
    "section": "",
    "text": "If you regularly work with remote, screenless machines, you probably regularly work with SSH too. SSH is great to access a machine, but what if it sits behind a router or firewall and you can‚Äôt change the rules? That‚Äôs what this is article is about: reverse tunnels!\n\nThe typical SSH connection\nThe simplest scenario is a direct connection between host A and B. Let‚Äôs say A wants to SSH into B. You simply type ssh username@B in a terminal in host A.\n\nSimple enough. This is just a normal SSH connection. Let‚Äôs get into tunnels.\n\n\nThe forward tunnel\nYou use tunnels when you want to forward connections in specific ports. Let‚Äôs say A wants to access a Jupyter Notebook server running on host B, on port 8888, and we want to be able to access it in host A as if it were running locally, on the same port. We can use a tunnel, that will forward all connections in port 8888 of host A to port 8888 of host B.\nIf you go to a browser in host A and access localhost:8888, sure enough, you‚Äôd get the Jupyter Notebook page (that is served on host B).\n\nBut what if host B sits behind a router or firewall? Well, no problem, you just need to create a port forwarding rule that ensures that a connection to routerB will be forwarded to the SSH port of host B. Let‚Äôs say port 22 (default SSH port) of routerB is being forwarded to port 22 of host B.\n\n\nIf B sits behind a router, you just need to make sure there is a port forwarding rule from port 22 of routerB to port 22 of B. But what if you can‚Äôt configure the router or firewall?\n\n\n\nThe reverse tunnel\nThat‚Äôs where reverse tunnels enter the picture. You can‚Äôt access host B with a SSH connection, because B is fenced. There is no way in. But, if you have direct access to it, if you can directly configure it (e.g.¬†manually), then you can still make the connection work by using a reverse tunnel. We still have the same scenario, that is, we want A to be able to access, locally, the Jupyter Notebook running in host B (this could be any service, really).\nBefore, we used the -L option, which forwarded local connection on port 8888 of A to port 8888 of B. We still want to do that, but now the SSH connection will start from host B. If we used -L again, we‚Äôd be forwarding connections on port 8888 of B to port 8888 of A, exactly the opposite of what we want. We need to reverse this, by using -R option instead. It works exactly as -L, but in a different direction.\n\nNote that the SSH connection is initiated from B to A, but the forwarded connections inside the tunnel are from A to B. Notice how the purple arrow (initial SSH connection) is now going leftwards, but the blue arrow (the forwarding tunnel) is still going towards the right.\nWith this, you‚Äôre done. You can, once again, access the Jupyter Notebook in port 8888 of localhost in host A and it will be served pages from host B (port 8888).\n\n\nSSH into a firewalled host with a reverse tunnel\nLet‚Äôs forget about Jupyter Notebooks for now. The more common case is just making a SSH connection into a firewalled host. Using a reverse tunnel, it‚Äôs easy. Let‚Äôs break it apart:\n\nB initiates a SSH connection to A: ssh anotherUser@A\nThis is the base command. We then add the reverse tunnel on top of that, to forward connection on port X of A (let‚Äôs give it a number, say 12345) to port 22 of B. B actually executes ssh -R 12345:[localhost](http://localhost):22 anotherUser@A. Now A can access port 22 of localhost of host B if it makes connections on port 12345 on localhost of A (the diagram below clarafies this).\nThen you can just type ssh -p 12345 username@localhost to have an interactive SSH session in a terminal in host A. This will initiate a SSH connection in port 12345 of localhost, which is forwarded, by the reverse tunnel, to port 22 of host B, creating the desired connection.\n\nWith this inceptionesque scenario, we have a SSH connection (blue arrow, initiated by A) inside another SSH connection (big pink arrow, initiated by B).\n\nWe‚Äôve now covered the typical ways both normal and reverse tunnels are used. You can use this knowledge to have communication rolling even when you have to deal with pesky firewalls and inaccessible routers.\nA convoluted, but common setup, is having a router sitting between A and the internet (check the diagram below). Let‚Äôs say we have a routerA that forwards port 6789 to port 22 (SSH‚Äôs default port) of host A. The goal is still the same: have host A access the firewalled host B. This is not really that much more complex, but we have to ‚Äúdivide and conquer‚Äù the problem, or layer it:\n\nHost B must create a SSH connection to host A. This was done with ssh anotherUser@A.\nBut now, A is behind routerA and port 6789 of routerA is forwarding to port 22 of A, so we have to specify that port in the original SSH connection: ssh anotherUser@routerA -p 6789. Since port 6789 of routerA is forwarding to port 22 of A, we get our connection.\nB must create a reverse tunnel. This part we already covered: ssh -R 12345:localhost:22 anotherUser@routerA -p 6789.\nFinally, host A connects to host B as before, ssh -p 12345 username@localhost\n\n\nWhat if we also can‚Äôt configure routerA? That means no port forwarding is in place and neither A nor B can receive connections! The only way out of that one is to make a blood sacrifice. Chickens üêî usually do it. Goats üêê if you want to get fancy. Or, perhaps, with a third host, with tunnels initiated in A and B‚Ä¶ That‚Äôs homework material!\nSources\nhttps://unix.stackexchange.com/questions/46235/how-does-reverse-ssh-tunneling-work"
  },
  {
    "objectID": "blog/display-video-in-a-python-gui-with-dear-pygui/index.html",
    "href": "blog/display-video-in-a-python-gui-with-dear-pygui/index.html",
    "title": "Display video in a Python GUI with Dear PyGui",
    "section": "",
    "text": "We‚Äôll cover the ground on how to display frames (from a live UDP video stream) on a GUI using Python. We‚Äôll use av for decoding the video. This will make this work with mostly any video that ffmpeg also supports (which is basically all), but we won‚Äôt add logic to ensure the play rate matches the encoded FPS, since this is meant for live video. We‚Äôll use Dear PyGui for the GUI management. Dear PyGui is fast, light on its dependencies and cross-platform.\nLet‚Äôs start writing a simple generator for the outputing video frames.\nimport av\nimport sys\n\nfn = sys.argv[1]\n\ndef load_video(fn):\n    video = av.open(fn)\n    fmt = 'rgb24'\n    for f in video.decode():\n        cf = f.to_ndarray(format=fmt)  # convert to rgb\n        yield cf\n    video.close()\nSimple stuff. We‚Äôre receiving the path of the video source from an argument. The load_video receives the path for the video source, opens it and starts decoding. Every decoded frame is converted to RGB and yielded from the generator.\nNext, let‚Äôs create the GUI.\nimport dearpygui.dearpygui as dpg\n\nw,h,d = 1280*2 ,720*2 ,3  # the width and height values are overdimensioned to fit a wider range of resolutions\nraw_data = np.zeros((h,w,d), dtype=np.float32)\nWe‚Äôll use a raw texture, as they are high performance and the preferred method when updating large textures every frame. This is exactly our use case, since Dear PyGui does not have a default video widget (as of version 1.3.1) and we update each frame to the GUI as we receive it.\nIn this use case we‚Äôll create a overdimensioned texture to allow frame size to change during the stream. If you know the resolution of the video doesn‚Äôt change, you can read them from the first frame and configure the texture afterwards.\nThis raw_data array will be the source of data for the GUI. Next, we‚Äôll create the texture repository.\nwith dpg.texture_registry(show=False):\n    dpg.add_raw_texture(w, h, raw_data, format=dpg.mvFormat_Float_rgb, tag=\"texture_tag\")\nWe‚Äôre predefining the texture format. This is compatible with the format chosen for the conversion happening inside the generator, with the av library. Let‚Äôs write the update function.\ndef update_dynamic_texture(new_frame):\n    global raw_data\n    h2, w2, d2 = new_frame.shape\n    raw_data[:h2, :w2] = new_frame[:,:] / 255\nThe update function receives the new frame of the video. We‚Äôll get the shape of the new frame, since we‚Äôre allowing for it to change over time and be drawn over the same texture. The caveat here is that it must be encoded with the same format (in our case, RGB). The frame received comes with pixels within the interval [0, 255] (8 bits per color channel), but Dear PyGui uses a float in the [0.0, 1.0] range, so we divide the new frame by 255. Let‚Äôs create the window.\nwith dpg.window(label=\"Video player\"):\n    dpg.add_image(\"texture_tag\")\nIt‚Äôs that easy. This is one of the reasons Dear PyGui is so great. The .window method creates a window and a context in which we can add other items on that same window. In our case, we just added a image element that renders the previously defined texture. Let‚Äôs take care of the viewport and setup of the GUI.\ndpg.create_viewport(title='Dashboard', width=800, height=600)\ndpg.setup_dearpygui()\ndpg.show_viewport()\nAgain, very simple stuff. We‚Äôre creating a viewport with a standard size. Afterwards, we just do the standard setup and display that viewport. Normally, we would now run start_dearpygui to start the automatic render loop, but we‚Äôll define our own render loop to receive and feed the new frames to the GUI.\nvideo_gen = load_video(fn)\nfor f in video_gen:\n    if dpg.is_dearpygui_running():\n        update_dynamic_texture(f)\n        dpg.render_dearpygui_frame()\n    else:\n        break  # deal with this scenario appropriately\n\ndpg.destroy_context()\nWe start by creating the video generator with load_video. Afterwards, we iterate over the video frames from the generator. If the Dear PyGui backend is running, we render the obtained frame. At the end of the script, we destroy the GUI context. I ran the script giving the path to the video source as the first (and only) argument. On my system, the result is the following.\n\n\n\nResulting GUI.\n\n\nI‚Äôm running this program on a Linux host, with the i3 window manager. Dear PyGui created the (resizable) video window inside the view port. This is basically a window inside the program window.\nMy test stream has several resolution changes over its duration. The other resolution is smaller then the one displayed above.\nThis is it. Very simple. This is not an ideal GUI, but it will get you started.\nWith this approach, we need to make sure we have an oversized texture that is bigger than any video resolution we might receive. A possible solution could be to create a new window and texture anytime a new resolution comes along and render the new frame on the texture for its resolution. Or, anytime a bigger resolution comes along, simply replace the old one with a bigger one that fits the new resolution.\nWe could also set the video window as primary, and it basically mean the viewport window and the video window are the same, i.e.¬†no window inside window. All other windows would be rendered above the video."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Diogo Silva",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\nSep 3, 2023\n\n\nThe pain of sorting images by faces II\n\n\n3 min\n\n\n\n\nAug 25, 2023\n\n\nThe pain of sorting images by faces I\n\n\n4 min\n\n\n\n\nFeb 25, 2022\n\n\nDisplay video in a Python GUI with Dear PyGui\n\n\n5 min\n\n\n\n\nMay 27, 2021\n\n\nReusable dropdown in Elm with parameterized types ‚Äî part II\n\n\n27 min\n\n\n\n\nApr 27, 2021\n\n\nElm, elm-ui and the building of a dropdown‚Ää‚Äî‚ÄäPart I\n\n\n14 min\n\n\n\n\nMar 27, 2021\n\n\nBypass firewalls and routers with reverse tunnels\n\n\n5 min\n\n\n\n\nJan 28, 2021\n\n\nHow to get unique values in an Elm list?\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/notes_estimation_classification/l1.html",
    "href": "research/notes_estimation_classification/l1.html",
    "title": "Lecture 1 - Probability basics",
    "section": "",
    "text": "What is the probability of an event \\(A\\) being observed \\(k\\) times in \\(n\\) random experiments\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\n\n\nn = 100\nk_max = 100\np = 1/6\n\ndef binomial(n: int, k: int) -&gt; float:\n    return math.comb(n, k) * p**k * (1-p)**(n-k)\n\nk_bin = [binomial(n, k_i) for k_i in range(1,k_max)]\n\nplt.bar(range(1,k_max), k_bin)\nplt.xlabel(\"k\")\nplt.ylabel(\"P\")\n\nprint(f\"# experiments: {n}\")\nprint(f\"sum over all k: {sum(k_bin)}\")\n\n\n# experiments: 100\nsum over all k: 0.9999999879253292"
  },
  {
    "objectID": "research/notes_estimation_classification/l1.html#discrete",
    "href": "research/notes_estimation_classification/l1.html#discrete",
    "title": "Lecture 1 - Probability basics",
    "section": "Discrete",
    "text": "Discrete\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport random\n\nn = 10\np = np.random.randint(10,50,n)\np = p / np.linalg.norm(p)\nprint(p)\n\nx = np.array([1, 1, 1, 2, 2, 2])\ny = np.array([1, 2, 3, 1, 2, 3])\nP = np.array([.1, .2, .1, .3, .1, .2])\n\n\n[0.279 0.375 0.347 0.443 0.193 0.375 0.279 0.231 0.279 0.279]"
  },
  {
    "objectID": "research/notes_estimation_classification/l1.html#section",
    "href": "research/notes_estimation_classification/l1.html#section",
    "title": "Lecture 1 - Probability basics",
    "section": "1",
    "text": "1\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\n\nx = np.array([1, 1, 1, 2, 2, 2])\nx_vals = np.sort(np.unique(x))\n\ny = np.array([1, 2, 3, 1, 2, 3])\ny_vals = np.sort(np.unique(y))\n\nP_xy = np.array([.1, .2, .1, .3, .1, .2])\n# rows = X, cols=Y\nP_xy = P_xy.reshape((2,3))\n\n# i P(x) marignal\nP_x = P_xy.sum(axis=1)\n\n# ii P(Y) marginal\nP_y = P_xy.sum(axis=0)\n\n# iii P(x|y)\n# P_x_cond_y = P(x,y) / p(y)\n\nP_x_cond_y = P_xy / P_y\n\n# iv E{x}\nE_x = sum( x_vals * P_x)\n\n# v E{Y}\n\nE_y = sum(y_vals * P_y)\n\n# vi E{x+y} = E[x] + E[y]\nE_xpy = E_x + E_y\n\n\n# vii E{xy}=??"
  },
  {
    "objectID": "research/notes_estimation_classification/l1.html#section-1",
    "href": "research/notes_estimation_classification/l1.html#section-1",
    "title": "Lecture 1 - Probability basics",
    "section": "2",
    "text": "2\nThe meaning of variables x,y,z is the following : x-there is gas in the tank; y ‚Äì battery is OK; z- motor starts at first attempt. Define a probability distribution for these variables.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\nx = [0, 1]\ny = [0, 1]\nz = [0, 1]\n\n# last column is probability\nP_xyz = [\n  (0, 0, 0, 0),\n  (0, 0, 1, 0.025),\n  (0, 1, 0, 0.025),\n  (0, 1, 1, 0.1),\n  (1, 0, 0, 0.025),\n  (1, 0, 1, 0.1),\n  (1, 1, 0, 0.025),\n  (1, 1, 1, 0.7),\n]"
  },
  {
    "objectID": "research/notes_estimation_classification/l1.html#section-2",
    "href": "research/notes_estimation_classification/l1.html#section-2",
    "title": "Lecture 1 - Probability basics",
    "section": "3",
    "text": "3\n\nA random variable x~N(0,R) has an uncertainty ellipsoid with semi axis major [3 1], minor [-.2 .6].\n\nCompute the covariance matrix R knowing that \\(E\\{{x_1}^2\\}=1\\).\nThe geometric interpretation of the ellipsoid of the covariance matrix is that the direction of the axis is the eigen vector and the length of the axis is the eigen value.\n\nLet a1 and a2 be the semi major and semi minor axis vectors, respectevely.\nSince we are given the major and minor semi axis, after normalizing we get the covariance matrix eigenvectors \\(e_1\\) and \\(e_2\\)\nHowever, the relationship between the uncertainty ellipsoid of the covariance matrix and its corresponding eigenvectors and eigenvalues is \\(axis=\\alpha \\sqrt{\\lambda_i} e_i\\).\nFrom this, we can write \\(axis_i = \\alpha \\sqrt{\\lambda_i} e_i \\rightarrow ||axis_i|| = \\alpha \\sqrt{\\lambda_i}\\)\nWe can easily find the eigenvector, but the axis magnitude will not be the eigenvalue, because we can draw many uncertainty ellipsoids depending on the uncertainty we wish to target (modeled with \\(\\alpha\\)). These ellipsoids will be concentric.\nSo, we want to compute the 2 eigenvalues and the alpha.\nFrom the axis equation above, we can write 2 equations and then we can use the following for the third:\n\n\\(Cov = \\sum_{i}{\\lambda_i e_i e_i^T}\\)\nThis means that the first element of the covariance matrix is \\(\\sum_{}{\\lambda_i e_{i_1}^2}\\)\nAnd since we know that the variance of \\(x_1\\) is 1, we know that \\(\\sum_{}{\\lambda_i e_{i_1}^2} = 1\\)\n\nThe resulting equations are:\n\n\\(\\alpha = \\sum_{i}{||a_i|| e_{i_1}^2}\\)\n\nIf the variance of \\(x_1\\) was different then 1, we would just multiply that in the left hand side of the equation.\n\n\\(\\lambda_i = \\frac{||a_i||}{\\alpha}\\)\n\n\n\n\nCode\nimport numpy as np\n\n# ellipsoid major and minor axis\na1 = np.array([[3,1]])\na2 = np.array([[-0.2, 0.6]])\n\na1_norm = np.linalg.norm(a1)\na2_norm = np.linalg.norm(a2)\n\ne1 = a1/a1_norm\ne2 = a2/a2_norm\n\n\nalpha = a1_norm * e1[0][0]**2 + a2_norm * e2[0][0]**2\nlambda_1 = a1_norm / alpha\nlambda_2 = a2_norm / alpha\n\n\n\nprint(f\"eigen values = {lambda_1, lambda_2}\")\nprint(f\"alpha = {alpha}\")\n\nprint(f\"eigen vectors = {e1, e2}\")\n\n\nR = lambda_1 * e1 * e1.T + \\\n    lambda_2 * e2 * e2.T\nnp.set_printoptions(precision=3)\nprint('R=\\n', R)\n\n\neigen values = (1.0869565217391306, 0.2173913043478261)\nalpha = 2.909295447354909\neigen vectors = (array([[0.949, 0.316]]), array([[-0.316,  0.949]]))\nR=\n [[1.    0.261]\n [0.261 0.304]]"
  },
  {
    "objectID": "research/notes_estimation_classification/l1.html#section-3",
    "href": "research/notes_estimation_classification/l1.html#section-3",
    "title": "Lecture 1 - Probability basics",
    "section": "4",
    "text": "4\n\nWe known that a bridge falls with probability .8 if the main structure elements break and this happens with probability .001. Which is the break probability knowing that the bridge has fallen? Discuss if this problem can be solved\n\nWe have 2 r.v. that take the following values: {\\(B_{falls}\\), \\(B_{stands}\\)} and {\\(E_{breaks}\\), \\(E_{nobreak}\\)}.\nWe know:\n\n\\(P(E_{breaks}) = 0.0001\\), this is the marginal\n\\(P(B_{falls} | E_{breaks}) = 0.8\\), this is the conditional\n\nWe want to know \\(P(E_{breaks} | B_{falls})\\).\nFrom \\(P(B_{falls} | E_{breaks}) = 0.8 = \\frac{P(B_{falls}, E_{breaks})}{P(E_{breaks})}\\)\nWe can deduce that \\(P(B_{falls}, E_{breaks}) = 0.8 \\times 0.0001\\)\nBut, we don‚Äôt know the marginal for \\(P(B_{falls})\\), so we can‚Äôt compute the conditional \\(P(E_{breaks} | B_{falls}) = \\frac{P(B_{falls}, E_{breaks})}{P(B_{falls})}\\)"
  },
  {
    "objectID": "research/notes_estimation_classification/l1.html#section-4",
    "href": "research/notes_estimation_classification/l1.html#section-4",
    "title": "Lecture 1 - Probability basics",
    "section": "5",
    "text": "5\n\nThree prisoners A, B, C are in separate cells. One is going to be released and the other two will be condemned to die. Prisoner A asks the jailer to deliver a farewell letter to one of the other prisoners which will be condemned. The next day the jailer tells him that he delivered the letter to prisoner B. What is the probability of A being set free before and after the jailer answer?\n\nThe distribution is the following (r=released, c=condemned)0\n\n\n\nA\nB\nC\n\n\n\n\nr\nc\nc\n\n\nc\nr\nc\n\n\nc\nc\nr\n\n\n\n\nWe want to know \\(P(A=r)\\) and \\(P(A=r | B=c)\\).\nSince there is only one scenario where A is released, \\(P(A=r) = \\frac{1}{3}\\)\nSince there are 2 scenarios where B is condemned, \\(P(B=c) = \\frac{2}{3}\\)\nSince there is only one scenario where A is released and B is condemned, \\(P(A=r, B=c) = \\frac{1}{3}\\)\n\\(P(A=r | B=c) = \\frac{P(A=r, B=c)}{P(B=c)} = \\frac{1/3}{2/3} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "research/notes_estimation_classification/l1.html#work",
    "href": "research/notes_estimation_classification/l1.html#work",
    "title": "Lecture 1 - Probability basics",
    "section": "Work",
    "text": "Work\nLet x be a random variable with distribution N(0,1). Determine in an exact or approximate way:\n\\(E\\{x^2\\}\\), \\(E\\{x^4\\}\\), \\(E\\{cos(x)\\}\\), \\(E\\{tan(x)\\}\\), \\(E\\{tan^{-1}(x)\\}\\)\n\n\nCode\nimport sympy\nimport math\n\ndef normal_pdf(x, mean, var):\n    left = 1 / (var * (2*math.pi)**(1/2))\n    over = -0.5 * ((x - mean) / var) ** 2\n    return left * sympy.exp(over)\n\n\nx = sympy.symbols(\"x\")\nmean = 0\nvar = 1\n\nv = x\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E) # should be 0, since mean is 0\nprint(\"\")\n\n\nv = x**2\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E) \nprint(\"\")\n\n\nv = x**4\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E) \nprint(\"\")\n\n\nv = sympy.cos(x)\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E)\nprint(\"\")\n\n\n\nv = sympy.tan(x)\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E)\nprint(\"\")\n\n\nv = sympy.atan(x)\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E)\nprint(\"\")\n\n\nvariable: x\ndist: 0.398942280401433*exp(-0.5*x**2)\nE 0\n\nvariable: x**2\ndist: 0.398942280401433*exp(-0.5*x**4)\nE 0.335469133482707*gamma(3/4)\n\nvariable: x**4\ndist: 0.398942280401433*exp(-0.5*x**8)\nE 0.153813275887005*gamma(5/8)\n\nvariable: cos(x)\ndist: 0.398942280401433*exp(-0.5*cos(x)**2)\nE 0.398942280401433*Integral(exp(-0.5*cos(x)**2)*cos(x), (x, -oo, oo))\n\nvariable: tan(x)\ndist: 0.398942280401433*exp(-0.5*tan(x)**2)\nE 0.398942280401433*Integral(exp(-0.5*tan(x)**2)*tan(x), (x, -oo, oo))\n\nvariable: atan(x)\ndist: 0.398942280401433*exp(-0.5*atan(x)**2)\nE 0.398942280401433*Integral(exp(-0.5*atan(x)**2)*atan(x), (x, -oo, oo))\n\n\n\nThere are 3 indefinite integrals. Let‚Äôs take a look at the corresponding pdfs.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.linspace(-20, 20)\n\n\ntransforms = {\n  'x': lambda x: x,\n  'x**2': lambda x: x**2,\n  'x**4': lambda x: x**4,\n  'cos(x)': lambda x: np.cos(x),\n  'tan(x)': lambda x: np.tan(x),\n  'atan(x)': lambda x: np.arctan(x)\n}\n\nfor l, t in transforms.items():\n  f = (1/((2*math.pi)**(1/2))) * np.exp(-0.5 * t(x)**2)\n  plt.plot(x, f)\nplt.legend(transforms.keys())\nplt.title(\"Normal distribution with several transformations\")\n\n\nText(0.5, 1.0, 'Normal distribution with several transformations')"
  },
  {
    "objectID": "phd/lectures_notes/estimation/l1.html",
    "href": "phd/lectures_notes/estimation/l1.html",
    "title": "Lesson 1 - Probability",
    "section": "",
    "text": "What is the probability of an event \\(A\\) being observed \\(k\\) times in \\(n\\) random experiments\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\nn = 100\nk_max = 100\np = 1/6\n\ndef binomial(n: int, k: int) -&gt; float:\n    return math.comb(n, k) * p**k * (1-p)**(n-k)\n\nk_bin = [binomial(n, k_i) for k_i in range(1,k_max)]\n\nplt.bar(range(1,k_max), k_bin)\nplt.xlabel(\"k\")\nplt.ylabel(\"P\")\n\nprint(f\"# experiments: {n}\")\nprint(f\"sum over all k: {sum(k_bin)}\")\n\n\n# experiments: 100\nsum over all k: 0.9999999879253292"
  },
  {
    "objectID": "phd/lectures_notes/estimation/l1.html#problem-1",
    "href": "phd/lectures_notes/estimation/l1.html#problem-1",
    "title": "Lesson 1 - Probability",
    "section": "Problem 1",
    "text": "Problem 1\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\n\nx = np.array([1, 1, 1, 2, 2, 2])\nx_vals = np.sort(np.unique(x))\n\ny = np.array([1, 2, 3, 1, 2, 3])\ny_vals = np.sort(np.unique(y))\n\nP_xy = np.array([.1, .2, .1, .3, .1, .2])\n# rows = X, cols=Y\nP_xy = P_xy.reshape((2,3))\n\n# i P(x) marignal\nP_x = P_xy.sum(axis=1)\n\n# ii P(Y) marginal\nP_y = P_xy.sum(axis=0)\n\n# iii P(x|y)\n# P_x_cond_y = P(x,y) / p(y)\n\nP_x_cond_y = P_xy / P_y\n\n# iv E{x}\nE_x = sum( x_vals * P_x)\n\n# v E{Y}\n\nE_y = sum(y_vals * P_y)\n\n# vi E{x+y} = E[x] + E[y]\nE_xpy = E_x + E_y\n\n\n# vii E{xy}=??"
  },
  {
    "objectID": "phd/lectures_notes/estimation/l1.html#problem-2",
    "href": "phd/lectures_notes/estimation/l1.html#problem-2",
    "title": "Lesson 1 - Probability",
    "section": "Problem 2",
    "text": "Problem 2\nThe meaning of variables x,y,z is the following : x-there is gas in the tank; y ‚Äì battery is OK; z- motor starts at first attempt. Define a probability distribution for these variables.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n\nx = [0, 1]\ny = [0, 1]\nz = [0, 1]\n\n# last column is probability\nP_xyz = [\n  (0, 0, 0, 0),\n  (0, 0, 1, 0.025),\n  (0, 1, 0, 0.025),\n  (0, 1, 1, 0.1),\n  (1, 0, 0, 0.025),\n  (1, 0, 1, 0.1),\n  (1, 1, 0, 0.025),\n  (1, 1, 1, 0.7),\n]"
  },
  {
    "objectID": "phd/lectures_notes/estimation/l1.html#problem-3",
    "href": "phd/lectures_notes/estimation/l1.html#problem-3",
    "title": "Lesson 1 - Probability",
    "section": "Problem 3",
    "text": "Problem 3\n\nA random variable x~N(0,R) has an uncertainty ellipsoid with semi axis major [3 1], minor [-.2 .6].\n\nCompute the covariance matrix R knowing that \\(E\\{{x_1}^2\\}=1\\).\nThe geometric interpretation of the ellipsoid of the covariance matrix is that the direction of the axis is the eigen vector and the length of the axis is the eigen value.\n\nLet a1 and a2 be the semi major and semi minor axis vectors, respectevely.\nSince we are given the major and minor semi axis, after normalizing we get the covariance matrix eigenvectors \\(e_1\\) and \\(e_2\\)\nHowever, the relationship between the uncertainty ellipsoid of the covariance matrix and its corresponding eigenvectors and eigenvalues is \\(axis=\\alpha \\sqrt{\\lambda_i} e_i\\).\nFrom this, we can write \\(axis_i = \\alpha \\sqrt{\\lambda_i} e_i \\rightarrow ||axis_i|| = \\alpha \\sqrt{\\lambda_i}\\)\nWe can easily find the eigenvector, but the axis magnitude will not be the eigenvalue, because we can draw many uncertainty ellipsoids depending on the uncertainty we wish to target (modeled with \\(\\alpha\\)). These ellipsoids will be concentric.\nSo, we want to compute the 2 eigenvalues and the alpha.\nFrom the axis equation above, we can write 2 equations and then we can use the following for the third:\n\n\\(Cov = \\sum_{i}{\\lambda_i e_i e_i^T}\\)\nThis means that the first element of the covariance matrix is \\(\\sum_{}{\\lambda_i e_{i_1}^2}\\)\nAnd since we know that the variance of \\(x_1\\) is 1, we know that \\(\\sum_{}{\\lambda_i e_{i_1}^2} = 1\\)\n\nThe resulting equations are:\n\n\\(\\alpha = \\sum_{i}{||a_i|| e_{i_1}^2}\\)\n\nIf the variance of \\(x_1\\) was different then 1, we would just multiply that in the left hand side of the equation.\n\n\\(\\lambda_i = \\frac{||a_i||}{\\alpha}\\)\n\n\n\n\nCode\nimport numpy as np\n\n# ellipsoid major and minor axis\na1 = np.array([[3,1]])\na2 = np.array([[-0.2, 0.6]])\n\na1_norm = np.linalg.norm(a1)\na2_norm = np.linalg.norm(a2)\n\ne1 = a1/a1_norm\ne2 = a2/a2_norm\n\n\nalpha = a1_norm * e1[0][0]**2 + a2_norm * e2[0][0]**2\nlambda_1 = a1_norm / alpha\nlambda_2 = a2_norm / alpha\n\n\n\nprint(f\"eigen values = {lambda_1, lambda_2}\")\nprint(f\"alpha = {alpha}\")\n\nprint(f\"eigen vectors = {e1, e2}\")\n\n\nR = lambda_1 * e1 * e1.T + \\\n    lambda_2 * e2 * e2.T\nnp.set_printoptions(precision=3)\nprint('R=\\n', R)\n\n\neigen values = (1.0869565217391306, 0.2173913043478261)\nalpha = 2.909295447354909\neigen vectors = (array([[0.949, 0.316]]), array([[-0.316,  0.949]]))\nR=\n [[1.    0.261]\n [0.261 0.304]]"
  },
  {
    "objectID": "phd/lectures_notes/estimation/l1.html#problem-4",
    "href": "phd/lectures_notes/estimation/l1.html#problem-4",
    "title": "Lesson 1 - Probability",
    "section": "Problem 4",
    "text": "Problem 4\n\nWe known that a bridge falls with probability .8 if the main structure elements break and this happens with probability .001. Which is the break probability knowing that the bridge has fallen? Discuss if this problem can be solved\n\nWe have 2 r.v. that take the following values: {\\(B_{falls}\\), \\(B_{stands}\\)} and {\\(E_{breaks}\\), \\(E_{nobreak}\\)}.\nWe know:\n\n\\(P(E_{breaks}) = 0.0001\\), this is the marginal\n\\(P(B_{falls} | E_{breaks}) = 0.8\\), this is the conditional\n\nWe want to know \\(P(E_{breaks} | B_{falls})\\).\nFrom \\(P(B_{falls} | E_{breaks}) = 0.8 = \\frac{P(B_{falls}, E_{breaks})}{P(E_{breaks})}\\)\nWe can deduce that \\(P(B_{falls}, E_{breaks}) = 0.8 \\times 0.0001\\)\nBut, we don‚Äôt know the marginal for \\(P(B_{falls})\\), so we can‚Äôt compute the conditional \\(P(E_{breaks} | B_{falls}) = \\frac{P(B_{falls}, E_{breaks})}{P(B_{falls})}\\)"
  },
  {
    "objectID": "phd/lectures_notes/estimation/l1.html#problem-5",
    "href": "phd/lectures_notes/estimation/l1.html#problem-5",
    "title": "Lesson 1 - Probability",
    "section": "Problem 5",
    "text": "Problem 5\n\nThree prisoners A, B, C are in separate cells. One is going to be released and the other two will be condemned to die. Prisoner A asks the jailer to deliver a farewell letter to one of the other prisoners which will be condemned. The next day the jailer tells him that he delivered the letter to prisoner B. What is the probability of A being set free before and after the jailer answer?\n\nThe distribution is the following (r=released, c=condemned)0\n\n\n\n| A\n| B\n| C |\n\n\n\n\nr\nc\nc\n\n\nc\nr\nc\n\n\nc\nc\nr\n\n\n\n\nWe want to know \\(P(A=r)\\) and \\(P(A=r | B=c)\\).\nSince there is only one scenario where A is released, \\(P(A=r) = \\frac{1}{3}\\)\nSince there are 2 scenarios where B is condemned, \\(P(B=c) = \\frac{2}{3}\\)\nSince there is only one scenario where A is released and B is condemned, \\(P(A=r, B=c) = \\frac{1}{3}\\)\n\\(P(A=r | B=c) = \\frac{P(A=r, B=c)}{P(B=c)} = \\frac{1/3}{2/3} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "phd/lectures_notes/estimation/l1.html#work",
    "href": "phd/lectures_notes/estimation/l1.html#work",
    "title": "Lesson 1 - Probability",
    "section": "Work",
    "text": "Work\nLet x be a random variable with distribution N(0,1). Determine in an exact or approximate way:\n\\(E\\{x^2\\}\\), \\(E\\{x^4\\}\\), \\(E\\{cos(x)\\}\\), \\(E\\{tan(x)\\}\\), \\(E\\{tan^{-1}(x)\\}\\)\n\n\nCode\nimport sympy\nimport math\n\ndef normal_pdf(x, mean, var):\n    left = 1 / (var * (2*math.pi)**(1/2))\n    over = -0.5 * ((x - mean) / var) ** 2\n    return left * sympy.exp(over)\n\n\nx = sympy.symbols(\"x\")\nmean = 0\nvar = 1\n\nv = x\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E) # should be 0, since mean is 0\nprint(\"\")\n\n\nv = x**2\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E) \nprint(\"\")\n\n\nv = x**4\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E) \nprint(\"\")\n\n\nv = sympy.cos(x)\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E)\nprint(\"\")\n\n\n\nv = sympy.tan(x)\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E)\nprint(\"\")\n\n\nv = sympy.atan(x)\ndist = normal_pdf(v, mean, var)\nE = sympy.integrate(v * dist, (x, -sympy.oo, +sympy.oo))\nprint(\"variable:\", v)\nprint(\"dist:\", dist)\nprint(\"E\", E)\nprint(\"\")\n\n\nvariable: x\ndist: 0.398942280401433*exp(-0.5*x**2)\nE 0\n\nvariable: x**2\ndist: 0.398942280401433*exp(-0.5*x**4)\nE 0.335469133482707*gamma(3/4)\n\nvariable: x**4\ndist: 0.398942280401433*exp(-0.5*x**8)\nE 0.153813275887005*gamma(5/8)\n\nvariable: cos(x)\ndist: 0.398942280401433*exp(-0.5*cos(x)**2)\nE 0.398942280401433*Integral(exp(-0.5*cos(x)**2)*cos(x), (x, -oo, oo))\n\nvariable: tan(x)\ndist: 0.398942280401433*exp(-0.5*tan(x)**2)\nE 0.398942280401433*Integral(exp(-0.5*tan(x)**2)*tan(x), (x, -oo, oo))\n\nvariable: atan(x)\ndist: 0.398942280401433*exp(-0.5*atan(x)**2)\nE 0.398942280401433*Integral(exp(-0.5*atan(x)**2)*atan(x), (x, -oo, oo))\n\n\n\nThere are 3 indefinite integrals. Let‚Äôs take a look at the corresponding pdfs.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport math\n\nx = np.linspace(-20, 20)\n\n\ntransforms = {\n  'x': lambda x: x,\n  'x**2': lambda x: x**2,\n  'x**4': lambda x: x**4,\n  'cos(x)': lambda x: np.cos(x),\n  'tan(x)': lambda x: np.tan(x),\n  'atan(x)': lambda x: np.arctan(x)\n}\n\nfor l, t in transforms.items():\n  f = (1/((2*math.pi)**(1/2))) * np.exp(-0.5 * t(x)**2)\n  plt.plot(x, f)\nplt.legend(transforms.keys())\nplt.title(\"Normal distribution with several transformations\")\n\n\nText(0.5, 1.0, 'Normal distribution with several transformations')\n\n\n\n\n\nSince the pdf of cos(x), tan(x) and atan(x) have non negative values in the whole domain and were integrating \\(]-\\inf, \\inf[\\), we can‚Äôt compute the expected value?"
  },
  {
    "objectID": "phd/index.html",
    "href": "phd/index.html",
    "title": "Diogo Silva",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "phd.html",
    "href": "phd.html",
    "title": "Diogo Silva",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\nMar 27, 2021\n\n\nLesson 1 - Probability\n\n\n7 min\n\n\n\n\n\n\nNo matching items"
  }
]