<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Diogo Silva">

<title>Diogo Silva - Lesson 2 -</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../../styles.css">
<meta property="og:title" content="Diogo Silva - Lesson 2 -">
<meta property="og:description" content="">
<meta property="og:image" content="l2_files/figure-html/cell-2-output-2.png">
<meta property="og:site-name" content="Diogo Silva">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Diogo Silva</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../blog.html" rel="" target="">
 <span class="menu-text">blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../research/index.html" rel="" target="">
 <span class="menu-text">research</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/diogo-aos" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://sigmoid.social/@diogo" rel="" target=""><i class="bi bi-mastodon" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lesson 2 -</h1>
  <div class="quarto-categories">
    <div class="quarto-category">estimation-classification-course</div>
    <div class="quarto-category">phd</div>
    <div class="quarto-category">lecture-notes</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Diogo Silva </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">Invalid Date</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="overview" class="level1">
<h1>Overview</h1>
<ul>
<li>Classic estimation
<ul>
<li>Parabolic fit</li>
<li>Least mean squares</li>
<li>Estimation</li>
<li>Regression</li>
<li>Frequency estimation</li>
<li>Robustness</li>
<li>RANSAC</li>
<li>Exercises &amp; Work</li>
</ul></li>
<li>Classic probabilistic methods
<ul>
<li>classic vs bayesian</li>
<li>Maximum Likelihood</li>
<li>ML vs LS</li>
<li>Crámer-Rao bound</li>
<li>Monte-Carlo</li>
<li>Exercises</li>
</ul></li>
<li>Bibliography
<ul>
<li>Duda, Hart, Stork, Pattern Classification, Wiley, 2001.</li>
<li>J. Marques, Reconhecimento de Padrões. Métodos Estatísticos e Neuronais, IST Press, 1999</li>
</ul></li>
</ul>
</section>
<section id="exercises" class="level1">
<h1>Exercises</h1>
<section id="problem-1---linear-least-squares-predict-signal-at-t" class="level2">
<h2 class="anchored" data-anchor-id="problem-1---linear-least-squares-predict-signal-at-t">Problem 1 - linear least squares, predict signal at t</h2>
<p>Given a signal <span class="math inline">\(y=( y_1 , ..., y_N )\)</span>, determine the coefficients of the linear predictor</p>
<p><span class="math inline">\(y_t = a_1 y_{t-1} + ... a_p y_{t-p}, N&gt;&gt;P\)</span></p>
<p>using the least squares method.</p>
<hr>
<p>Let <span class="math inline">\(\theta = [a_1,..., a_p]^T\)</span> be the parameter set.</p>
<p>Error is given by</p>
<p><span class="math display">\[
E = \sum_{i}{(y_i - x_i \theta )^2}
\]</span></p>
<p>Where, for each <span class="math inline">\(y_i\)</span>, we have <span class="math inline">\(x_i = (y_{i-1}, ..., y_{i-p})\)</span>. This means, using historical data, we can’t use <span class="math inline">\(y_1, ..., y_p\)</span>.</p>
<p>We want to minimize <span class="math inline">\(\theta\)</span> such that <span class="math inline">\(E = 0\)</span>.</p>
<p><span class="math display">\[
\frac{\partial E}{\partial \theta_j} = \frac{\partial \sum_{i}{(y_i - x_i \theta )^2}}{\partial \theta_j} =
2 \sum_{i}{ \frac{\partial(y_i - x_i \theta )}{\partial \theta_j}} =
2 \sum_{i}{ -x_{i_j} \theta_j}
\]</span></p>
<p>We then have</p>
<p><span class="math display">\[
\frac{\partial E}{\partial \theta} =
\begin{bmatrix}
-2 \sum_{i}{x_{i_1} \theta_1} \\
\vdots \\
-2 \sum_{i}{x_{i_p} \theta_p} \\
\end{bmatrix}
= 0
\]</span></p>
<p>Solving this equation will give us the parameter values.</p>
</section>
<section id="problem-2---predict-signal-in-ttk-todo-recheck" class="level2">
<h2 class="anchored" data-anchor-id="problem-2---predict-signal-in-ttk-todo-recheck">Problem 2 - predict signal in [t,t+k] TODO RECHECK</h2>
<p>By increasing the prediction window, we’re increasing the number of parameters. If, for each prediction, we were looking at <span class="math inline">\(p\)</span> previous signals and using <span class="math inline">\(p\)</span> parameters for prediciting the next signal <span class="math inline">\(y_t\)</span>, now we’ll need <span class="math inline">\(k \times p\)</span> parameters for predicting <span class="math inline">\((y_t, ..., y_{t+k})\)</span>. We have</p>
<p><span class="math display">\[
\begin{bmatrix}
x_1 \\
\vdots \\
x_N
\end{bmatrix}
\times
\begin{bmatrix}
a_{1_1}  &amp; ... &amp; a_{k_1} \\
\vdots &amp;  &amp; \vdots \\
a_{1_p}  &amp; ... &amp; a_{k_p} \\
\end{bmatrix} =
\begin{bmatrix}
y_{1_1} &amp; ... &amp; y_{1_k} \\
\vdots &amp;  &amp; \vdots \\
y_{N_1}  &amp; ... &amp; y_{N_k} \\
\end{bmatrix}
\]</span></p>
<p>Since the prediciton at <span class="math inline">\(y_t\)</span> doesn’t affect subsequent predictions and the parameters for <span class="math inline">\(y_t\)</span></p>
<p><span class="math display">\[
\frac{\partial E}{\partial \theta} =
\begin{bmatrix}
-2 \sum_{i}{x_{i_1} \theta_{1_1}} &amp; ... &amp; -2 \sum_{i}{x_{i_1} \theta_{k_1}}\\
\vdots &amp; &amp; \vdots \\
-2 \sum_{i}{x_{i_p} \theta_{1_p}} &amp; ... &amp; -2 \sum_{i}{x_{i_p} \theta_{k_p}}
\end{bmatrix}
= 0
\]</span></p>
<hr>
</section>
</section>
<section id="least-squares-demo" class="level1">
<h1>Least squares demo</h1>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>dim <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>]</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>interval <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">200</span>]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>outlier_fraction <span class="op">=</span> <span class="fl">0.25</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">## create dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.randint(interval[<span class="dv">0</span>], interval[<span class="dv">1</span>], (N, <span class="dv">2</span>))</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>gt <span class="op">=</span> x[:,<span class="dv">0</span>] <span class="op">*</span> params[<span class="dv">0</span>] <span class="op">+</span> x[:,<span class="dv">1</span>] <span class="op">*</span> params[<span class="dv">1</span>]</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># add random noise</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> gt <span class="op">+</span> np.random.random(gt.shape)<span class="op">*</span><span class="fl">0.1</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># add outliers with 1000*N(0,1)</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.random.randint(<span class="dv">0</span>, N, <span class="bu">int</span>(outlier_fraction <span class="op">*</span> N))</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>y[idx] <span class="op">=</span> y[idx] <span class="op">+</span> np.random.rand(idx.size)<span class="op">*</span><span class="dv">1000</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(<span class="bu">range</span>(interval[<span class="dv">1</span>]), <span class="bu">range</span>(interval[<span class="dv">1</span>]))</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>z_plane <span class="op">=</span> xx<span class="op">*</span>params[<span class="dv">0</span>] <span class="op">+</span> yy<span class="op">*</span>params[<span class="dv">1</span>]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 3D plane</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(xx, yy, z_plane, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Set labels</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'x1'</span>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'x2'</span>)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="st">'y'</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="co">#and i would like to plot this point : </span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>ax.scatter(x[:,<span class="dv">0</span>], x[:,<span class="dv">1</span>], gt, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>ax.scatter(x[:,<span class="dv">0</span>], x[:,<span class="dv">1</span>], y, color<span class="op">=</span><span class="st">'purple'</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co"># when directly solving the linear equation X.theta = y, this is overdetermined, because there are many more equations than variables, so I'm just using the first #dim equations</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co"># if we were doing RANSAC, the number of samples each time would also be this if we were going for the naive simple linear model</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>z_gt <span class="op">=</span> np.linalg.solve(x[:dim, :dim],</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>                    gt[:dim])</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'z_gt='</span>, z_gt)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.linalg.solve(x.T.dot(x),</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>                    x.T.dot(y))</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'z='</span>, z)</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co"># plot estimated surface</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co"># z_hat_plane = xx*z[0] + yy*z[1]</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.plot_surface(xx, yy, z_hat_plane, alpha=0.8)</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="co"># compute sum of squared error with z model</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> x.dot(z)</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _y, _yhat <span class="kw">in</span> <span class="bu">zip</span>(y, y_hat):</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(_y, _yhat, (_y <span class="op">-</span> _yhat)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>sse <span class="op">=</span> np.<span class="bu">sum</span>((y <span class="op">-</span> y_hat)<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'sse='</span>, sse)</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>z_gt= [2. 3.]
z= [2.6715333 3.4231839]
553.0366554877959 634.1221847881386 6574.863061916739
581.0257073939612 729.9352564050216 22174.053786677414
706.0867243551226 839.0785985542243 17686.838602989705
436.0883220405556 538.0014400674104 10386.283625955628
400.050103945776 491.0820727130472 8286.819337645433
571.0883090483975 658.1659845190089 7582.521565365125
1016.1576347478971 290.45449888182077 526645.0414058568
415.0861508818276 482.49688585802977 4544.207190031764
431.0918303694193 564.6172218690871 17829.03017513955
571.9171882561097 151.86081678616068 176447.35521249982
1625.030696145146 819.4451511788888 648968.0702585818
857.3247650621568 700.4668776466159 24604.39684446649
575.0989066771549 699.7242464545636 15531.475314634574
1236.029957987714 827.1427208124517 167188.7727248192
544.0724355340316 649.5537394460689 11126.305474983583
551.0974787390737 661.8246862765171 12260.514489040064
386.02258012285387 449.016697441492 3968.2588167543445
967.8326087715739 825.5398683837752 20247.223967069458
344.0995120702039 402.2603549284794 3382.6836419850147
680.0934542491792 799.675737180125 14299.922390976766
771.0953554186798 928.8240111841434 24878.328849580113
369.0133982400601 426.8927804160254 3350.0228810714502
491.06650637328215 581.6786871736163 8210.567309392436
407.01354110871495 476.4836810738186 4826.100346771094
405.0795005309986 467.9709872335024 3955.339099651214
913.2904173037234 760.2458175881031 23422.64950211444
734.0823177242754 904.5176353792988 29048.197504168722
346.0286327139974 432.9694588089635 7558.707242075138
187.04060749820528 244.53131938750994 3305.1819535390364
605.8540599656659 691.2205720202217 7287.441380360613
925.0011912304478 1122.849754474483 39144.05397772899
1462.0524581657885 716.3420720318195 556083.9799880731
908.0664724415496 992.1076474477622 7062.919096424853
1381.7148549650408 805.0097843810108 332588.738437331
243.02356875663963 283.11905655485594 1607.648141776913
606.0835281413412 735.8759681745315 16846.077489769315
1488.0859227821206 831.897161662636 430583.6902195241
1040.0321091221235 719.5932116859511 102681.08699010982
81.04825096364762 104.10828641309574 531.765234929804
577.0322903240711 663.8441202145444 7536.293808932472
1310.4000479520373 713.9060565844414 355805.08173764555
677.0298749054671 820.7854275335908 20665.65891141725
203.07132585381927 233.1930868083871 907.3204830041273
1293.1066328119318 1112.1636212607627 32740.373429206513
640.0691469459211 747.4133032189017 11522.767885958061
372.1159226880901 128.2426179706155 59474.18875382222
374.04613484522866 437.6604260504208 4046.7780455389884
100.01546009358442 131.2402009567469 974.9844419716479
391.09968769320244 467.9619678275282 5907.81010744757
842.0794439497741 1027.7522558317296 34474.393072152016
770.0160671325194 912.8853431902128 20411.63004124939
865.0028430141505 1054.3860764453548 35866.00910485802
862.0189587529121 1043.9534998996346 33100.17726226846
285.0525418412088 328.70716696049124 1905.7262943050869
381.03349599929135 476.80071135054584 9171.359536133554
871.0769387421601 1064.737140570399 37504.273772154265
211.01418749486257 253.22507688112523 1781.7591827793021
288.0339030007165 364.8408498685107 5899.307087152159
694.6146219685414 234.9409252664659 211299.90743975173
429.02144941821183 510.543475841058 6645.840792087231
496.01260262632667 584.268708056371 7789.1401456791
1612.657134581335 735.1333369824792 770048.0153523175
282.0169913465148 363.8356426024841 6694.29169334592
840.0450402142692 1007.5572409176409 28060.337384486687
732.026090575937 877.3132278209464 21108.35224885019
574.0079237941256 694.2996674270283 14470.103586243986
507.0234170245728 629.9202920707332 15103.641896111578
1151.4414306465806 665.6644516873243 235979.27328678165
333.01340626231706 392.8239662428119 3577.303085180368
618.0038231617749 744.8957753508482 16101.56753035407
544.0206830066902 670.5819173788594 16017.74604580715
534.0340242942499 664.2336435059729 16951.94084287766
280.0072658355876 330.79007450724555 2578.893656582219
516.0027919197345 642.5263079898571 16008.200118746567
400.0145897474584 493.4185369278017 8724.297348868366
424.04111049913604 560.5238997902795 18627.551772690673
414.0011397892196 526.138055340339 12574.687829318867
470.05127117017446 611.4550768027749 19995.036247382242
980.078779808502 1193.3963400503656 45504.381507541104
297.0152392654102 372.7739373581254 5739.380336703175
58.07333559932181 66.96037683307553 78.97950189043885
455.0966860296654 547.6098730004028 8558.68976348261
607.0956433894627 745.9734756315759 19287.052288268533
659.0505390909971 803.7510204469841 20938.22930465434
1351.561292728924 575.3213938947555 602548.38054208
356.0328548930314 474.3646959031676 14002.424596848152
280.0640258292103 331.9583066146228 2693.016378235232
389.02644038513137 486.3186124568887 9465.766746440433
567.0867034997347 676.1875600596939 11902.996902116793
829.0323530417264 992.2796916950871 26649.69357740502
630.0786425720895 743.4014935607695 12842.068556202568
710.8548073419885 586.4421474297748 15478.509946432148
834.0399785719956 1011.2249620811233 31394.518381129867
229.02503257678134 294.79235822265423 4325.34112261029
1044.9946303233187 557.7888928781226 237369.43059951733
680.0459630009796 804.3486656096339 15451.161875815575
316.0409052134162 396.4011555796448 6457.769838922948
182.05842786176063 232.59544164573725 2553.989762201843
243.08240285681748 287.79198498436494 1998.9467340199117
677.0300131763337 809.1031064598183 17443.30196946802
sse= 2561.921775742817</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="l2_files/figure-html/cell-2-output-2.png" width="414" height="396"></p>
</div>
</div>
<p>Example with wider estimation horizon window</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> np.array([</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    [<span class="op">-</span><span class="dv">5</span>,<span class="dv">6</span>],</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>]).T</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>interval <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">200</span>]</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>outlier_fraction <span class="op">=</span> <span class="fl">0.25</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">## create dataset</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.randint(interval[<span class="dv">0</span>], interval[<span class="dv">1</span>], (N, <span class="dv">2</span>))</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>gt <span class="op">=</span> [<span class="bu">sum</span>([x[:,d]<span class="op">*</span>params[h][d] <span class="cf">for</span> d <span class="kw">in</span> <span class="bu">range</span>(p)]) <span class="cf">for</span> h <span class="kw">in</span> <span class="bu">range</span>(k)]</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>gt <span class="op">=</span> np.column_stack(gt)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># add random noise</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> gt <span class="op">+</span> np.random.random(gt.shape)<span class="op">*</span><span class="fl">0.1</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># add outliers with 1000*N(0,1)</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>n_outliers <span class="op">=</span> <span class="bu">int</span>(outlier_fraction <span class="op">*</span> N)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.random.randint(<span class="dv">0</span>, N, n_outliers)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>y[idx] <span class="op">=</span> y[idx] <span class="op">+</span> np.random.random((n_outliers, k))<span class="op">*</span><span class="dv">1000</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(<span class="bu">range</span>(interval[<span class="dv">1</span>]), <span class="bu">range</span>(interval[<span class="dv">1</span>]))</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>z_planes <span class="op">=</span> [xx<span class="op">*</span>param[<span class="dv">0</span>] <span class="op">+</span> yy<span class="op">*</span>param[<span class="dv">1</span>] <span class="cf">for</span> param <span class="kw">in</span> params]</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Create figure</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 3D plane</span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(xx, yy, z_planes[<span class="dv">0</span>], alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(xx, yy, z_planes[<span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Set labels</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'x1'</span>)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'x2'</span>)</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="st">'y'</span>)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="co">#and i would like to plot this point : </span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>ax.scatter(x[:,<span class="dv">0</span>], x[:,<span class="dv">1</span>], gt[:,<span class="dv">0</span>], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>ax.scatter(x[:,<span class="dv">0</span>], x[:,<span class="dv">1</span>], gt[:,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="co">#ax.scatter(x[:,0], x[:,1], y, color='purple')</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a><span class="co"># when directly solving the linear equation X.theta = y, this is overdetermined, because there are many more equations than variables, so I'm just using the first #dim equations</span></span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a><span class="co"># if we were doing RANSAC, the number of samples each time would also be this if we were going for the naive simple linear model</span></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>z_gt <span class="op">=</span> np.linalg.solve(x[:p, :p],</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>                    gt[:p])</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'z_gt='</span>, z_gt)</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.linalg.solve(x.T.dot(x),</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>                    x.T.dot(y))</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'z='</span>, z)</span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a><span class="co"># plot estimated surface</span></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a><span class="co"># z_hat_plane = xx*z[0] + yy*z[1]</span></span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.plot_surface(xx, yy, z_hat_plane, alpha=0.8)</span></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a><span class="co"># compute sum of squared error with z model</span></span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> x.dot(z)</span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a><span class="co"># for _y, _yhat in zip(y, y_hat):</span></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a><span class="co">#     print(_y, _yhat, (_y - _yhat)**2)</span></span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>sse <span class="op">=</span> np.<span class="bu">sum</span>((y <span class="op">-</span> y_hat)<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'sse='</span>, sse)</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>z_gt= [[ 2.  3.]
 [-5.  6.]]
z= [[ 2.36886375  3.23070315]
 [-4.6814957   6.63804903]]
sse= 3374.364988030938</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="l2_files/figure-html/cell-3-output-2.png" width="413" height="396"></p>
</div>
</div>
</section>
<section id="ransac" class="level1">
<h1>Ransac</h1>
<p>Procedure •choose a minimal set of data allowing to estimate the parameters •compute the number of observations well approximated by the model •repeat the previous steps N times and at the end choose the estimate with bigger support (the estimate is refined using the support observations)KK</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co">Consider two parabolas and observations close to each of them.</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">However, we do not know which parabola fits each observation.</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">Estimate the coefficients of the parabolas using the least squares</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">method and robust methods.</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">Characterize the performance of both methods</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">'''</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some sample data points for a parabola</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> x <span class="op">+</span> <span class="dv">5</span>  <span class="co"># True parabola equation</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Add some random noise to the data to make it realistic</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">10</span>, <span class="bu">len</span>(x))</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>y_data <span class="op">=</span> y_true <span class="op">+</span> noise</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the design matrix (X) and the target vector (y)</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.column_stack((x<span class="op">**</span><span class="dv">2</span>, x, np.ones(<span class="bu">len</span>(x))))  <span class="co"># x^2, x, and a bias term</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y_data</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Use linear regression to fit a linear model</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>coefficients, residuals, _, _ <span class="op">=</span> np.linalg.lstsq(X, y, rcond<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the coefficients for the linear model</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>a, b, c <span class="op">=</span> coefficients</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted values using the linear model</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> a <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> b <span class="op">*</span> x <span class="op">+</span> c</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original data and the linear regression model</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>plt.scatter(x, y_data, label<span class="op">=</span><span class="st">'Sample Data with Noise'</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y_pred, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Linear Regression Model'</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y_true, <span class="st">'g'</span>, label<span class="op">=</span><span class="st">'True Parabola'</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Linear Regression on a Parabola'</span>)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the coefficients of the linear model</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated coefficients: a = </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">, b = </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">, c = </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="l2_files/figure-html/cell-4-output-1.png" width="668" height="523"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated coefficients: a = 1.9946968021437606, b = 2.9215716340764777, c = 5.022144628211501</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some sample data points for a quadratic relationship</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">50</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> x <span class="op">+</span> <span class="dv">5</span>  <span class="co"># True quadratic equation</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Add some random noise to the data to make it realistic</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">5</span>, <span class="bu">len</span>(x))</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>y_data <span class="op">=</span> y_true <span class="op">+</span> noise</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the parameters for the quadratic model (y = ax^2 + bx + c)</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Initial guess for the coefficient of x^2</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Initial guess for the coefficient of x</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> <span class="dv">1</span>  <span class="co"># Initial guess for the constant term</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Set hyperparameters for gradient descent</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>num_iterations <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform gradient descent to optimize the parameters</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the predicted values using the current parameters</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> a <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> b <span class="op">*</span> x <span class="op">+</span> c</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the gradients with respect to a, b, and c</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    gradient_a <span class="op">=</span> (<span class="op">-</span><span class="dv">2</span><span class="op">/</span><span class="bu">len</span>(x)) <span class="op">*</span> np.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> (y_data <span class="op">-</span> y_pred))</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    gradient_b <span class="op">=</span> (<span class="op">-</span><span class="dv">2</span><span class="op">/</span><span class="bu">len</span>(x)) <span class="op">*</span> np.<span class="bu">sum</span>(x <span class="op">*</span> (y_data <span class="op">-</span> y_pred))</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    gradient_c <span class="op">=</span> (<span class="op">-</span><span class="dv">2</span><span class="op">/</span><span class="bu">len</span>(x)) <span class="op">*</span> np.<span class="bu">sum</span>(y_data <span class="op">-</span> y_pred)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Update the parameters using the gradients and learning rate</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    a <span class="op">-=</span> learning_rate <span class="op">*</span> gradient_a</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    b <span class="op">-=</span> learning_rate <span class="op">*</span> gradient_b</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    c <span class="op">-=</span> learning_rate <span class="op">*</span> gradient_c</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted values using the optimized parameters</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> a <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> b <span class="op">*</span> x <span class="op">+</span> c</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original data and the quadratic regression model</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>plt.scatter(x, y_data, label<span class="op">=</span><span class="st">'Sample Data with Noise'</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.plot(x, y_true, 'g', label='True Quadratic Relationship')</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y_pred, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Quadratic Regression Model'</span>)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Quadratic Regression Using Gradient Descent'</span>)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the optimized coefficients of the quadratic model</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized coefficient of x^2 (a): </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized coefficient of x (b): </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Optimized constant term (c): </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="l2_files/figure-html/cell-5-output-1.png" width="674" height="523"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Optimized coefficient of x^2 (a): -1.326943229165013e+235
Optimized coefficient of x (b): -1.819006132630718e+218
Optimized constant term (c): -8.531796211876459e+233</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some sample data points for a quadratic relationship</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">20</span>, <span class="dv">20</span>, <span class="dv">200</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parabola(x,a,b,c,shift<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a<span class="op">*</span>(x<span class="op">-</span>shift)<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> b<span class="op">*</span>(x<span class="op">-</span>shift) <span class="op">+</span> c</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.ones_like(x)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>y_true[::<span class="dv">2</span>] <span class="op">=</span> parabola(x[::<span class="dv">2</span>], <span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">0</span>)<span class="co"># True quadratic equation</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># another parabola shifted in x to the right</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>y_true[<span class="dv">1</span>::<span class="dv">2</span>] <span class="op">=</span> parabola(x[<span class="dv">1</span>::<span class="dv">2</span>], <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Add some random noise to the data to make it realistic</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>y_data <span class="op">=</span> y_true <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="dv">50</span>, y_true.size)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co"># another parabola shifter to the right</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.reshape((x.size,<span class="dv">1</span>))</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> np.hstack([x<span class="op">**</span><span class="dv">2</span>, x, np.ones_like(x)])</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> np.linalg.pinv(xx).dot(y_true)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>a,b,c <span class="op">=</span> coefs</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted values using the linear model</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> a <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> b <span class="op">*</span> x <span class="op">+</span> c</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="co"># residuals</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_pred <span class="op">-</span> y_true</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>plt.scatter(x, y_data, label<span class="op">=</span><span class="st">'Sample Data with Noise'</span>)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y_pred, <span class="st">'r'</span>, label<span class="op">=</span><span class="st">'Linear Regression Model'</span>)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y_true, <span class="st">'g'</span>, label<span class="op">=</span><span class="st">'True Parabola'</span>)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Linear Regression on a Parabola'</span>)</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the coefficients of the linear model</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated coefficients: a = </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">, b = </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">, c = </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="l2_files/figure-html/cell-6-output-1.png" width="676" height="523"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated coefficients: a = 5.885261194029848, b = -57.27985074626854, c = 305.2713567839198</code></pre>
</div>
</div>
<ul>
<li>A parabola has 3 parameters, so the minimum number of points we need in each RANSAC sample is 3.</li>
<li>RANSAC is very sensitive to the threshold value. For 2 parabolas, if only changing x displacement and with sufficient noise, threshold must be set to a low value to find a solution close to the true parabolas.</li>
<li>By running RANSAC multiple times, we consistly obain a good aproximation of each parabola.</li>
<li>Interesting questions to answer:
<ul>
<li>what happens when there is more data available for one parabola? guess: the estimated model is only a good fit for the dominating parabola</li>
</ul></li>
</ul>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ransac</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">3</span> <span class="co"># sample size</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">50</span> <span class="co"># iterations</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>thresh <span class="op">=</span> <span class="dv">3</span> <span class="co"># max distance to model</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># data</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>var <span class="op">=</span> <span class="dv">10</span> <span class="co"># noise variance</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>parabolas <span class="op">=</span> [</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>),</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    (<span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">6</span>),</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some sample data points for a quadratic relationship</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">100</span> <span class="op">*</span> <span class="bu">len</span>(parabolas))</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parabola(x,a,b,c,shift<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a<span class="op">*</span>(x<span class="op">-</span>shift)<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> b<span class="op">*</span>(x<span class="op">-</span>shift) <span class="op">+</span> c</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.ones_like(x)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>step_size <span class="op">=</span> <span class="bu">len</span>(parabolas)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (a,b,c,shift) <span class="kw">in</span> <span class="bu">enumerate</span>(parabolas):</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>    y_true[i::step_size] <span class="op">=</span> parabola(x[i::step_size], a, b, c, shift)<span class="co"># True quadratic equation</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Add some random noise to the data to make it realistic</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>y_data <span class="op">=</span> y_true <span class="op">+</span> np.random.normal(<span class="dv">0</span>, var, y_true.size)</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.reshape((x.size,<span class="dv">1</span>))</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> np.hstack([x<span class="op">**</span><span class="dv">2</span>, x, np.ones_like(x)])</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a><span class="co"># ransac</span></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit_eval_model_sample(sample: <span class="bu">list</span>[<span class="bu">int</span>]):</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>    <span class="co">#coefs = np.linalg.pinv(xx[sample]).dot(y_data[sample])</span></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>    coefs <span class="op">=</span> np.linalg.inv(xx[sample]).dot(y_data[sample])</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>    a,b,c <span class="op">=</span> coefs</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> a <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> b <span class="op">*</span> x <span class="op">+</span> c</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>    residuals <span class="op">=</span> np.<span class="bu">abs</span>(y_pred.flatten() <span class="op">-</span> y_data)</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>    inliners <span class="op">=</span> np.arange(x.size)[residuals <span class="op">&lt;</span> thresh]</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coefs, inliners, inliners.size</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> [<span class="bu">sorted</span>(random.sample(<span class="bu">range</span>(x.size), s)) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(N)]</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a><span class="co">#models = [np.linalg.pinv(xx[sample]).dot(y_data[sample]) for sample in samples]</span></span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>fits <span class="op">=</span> [fit_eval_model_sample(sample) <span class="cf">for</span> sample <span class="kw">in</span> samples]</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>fits <span class="op">=</span> <span class="bu">sorted</span>(fits, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>_, inliners, _ <span class="op">=</span> fits[<span class="op">-</span><span class="dv">1</span>] <span class="co"># best model</span></span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f" using </span><span class="sc">{</span>inliners<span class="sc">.</span>size<span class="sc">}</span><span class="ss"> inliners"</span>)</span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> np.linalg.pinv(xx[inliners]).dot(y_data[inliners])</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>a,b,c <span class="op">=</span> coefs</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicted values using the linear model</span></span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> a <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> b <span class="op">*</span> x <span class="op">+</span> c</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a><span class="co"># residuals</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> y_pred <span class="op">-</span> y_true</span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>plt.scatter(x, y_data, label<span class="op">=</span><span class="st">'Sample Data with Noise'</span>)</span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a>plt.plot(x, y_pred,  <span class="st">'black'</span>, label<span class="op">=</span><span class="st">'RANSAC Model'</span>)</span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a><span class="co"># plot true parabolas</span></span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, _ <span class="kw">in</span> <span class="bu">enumerate</span>(parabolas):</span>
<span id="cb11-78"><a href="#cb11-78" aria-hidden="true" tabindex="-1"></a>    plt.plot(x[i::<span class="bu">len</span>(parabolas)], y_true[i::<span class="bu">len</span>(parabolas)], label<span class="op">=</span><span class="ss">f'True Parabola </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb11-79"><a href="#cb11-79" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb11-80"><a href="#cb11-80" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'y'</span>)</span>
<span id="cb11-81"><a href="#cb11-81" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb11-82"><a href="#cb11-82" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Least Squares on a Parabola'</span>)</span>
<span id="cb11-83"><a href="#cb11-83" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb11-84"><a href="#cb11-84" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb11-85"><a href="#cb11-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-86"><a href="#cb11-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the coefficients of the linear model</span></span>
<span id="cb11-87"><a href="#cb11-87" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated coefficients: a = </span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">, b = </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">, c = </span><span class="sc">{</span>c<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> using 23 inliners
Estimated coefficients: a = 6.377741219096249, b = -2.316764491130902, c = 6.473922828503258</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="l2_files/figure-html/cell-7-output-2.png" width="667" height="523"></p>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>